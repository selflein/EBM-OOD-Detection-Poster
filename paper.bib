
@article{arbelGeneralizedEnergyBased2020,
  title = {Generalized {{Energy Based Models}}},
  author = {Arbel, Michael and Zhou, Liang and Gretton, Arthur},
  year = {2020},
  month = oct,
  abstract = {We introduce the Generalized Energy Based Model (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the "generator"). GEBMs are trained by alternating between learning the energy and the base. We show that both training stages are well-defined: the energy is learned by maximising a generalized likelihood, and the resulting energy-based loss provides informative gradients for learning the base. Samples from the posterior on the latent space of the trained model can be obtained via MCMC, thus finding regions in this space that produce better quality samples. Empirically, the GEBM samples on image-generation tasks are of much better quality than those from the learned generator alone, indicating that all else being equal, the GEBM will outperform a GAN of the same complexity. When using normalizing flows as base measures, GEBMs succeed on density modelling tasks, returning comparable performance to direct maximum likelihood of the same networks.},
  archiveprefix = {arXiv},
  eprint = {2003.05033},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Arbel et al_2020_Generalized Energy Based Models.pdf},
  journal = {arXiv:2003.05033 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{behrmannInvertibleResidualNetworks2019,
  title = {Invertible {{Residual Networks}}},
  author = {Behrmann, Jens and Grathwohl, Will and Chen, Ricky T. Q. and Duvenaud, David and Jacobsen, J{\"o}rn-Henrik},
  year = {2019},
  month = may,
  abstract = {We show that standard ResNet architectures can be made invertible, allowing the same model to be used for classification, density estimation, and generation. Typically, enforcing invertibility requires partitioning dimensions or restricting network architectures. In contrast, our approach only requires adding a simple normalization step during training, already available in standard frameworks. Invertible ResNets define a generative model which can be trained by maximum likelihood on unlabeled data. To compute likelihoods, we introduce a tractable approximation to the Jacobian log-determinant of a residual block. Our empirical evaluation shows that invertible ResNets perform competitively with both state-of-the-art image classifiers and flow-based generative models, something that has not been previously achieved with a single architecture.},
  archiveprefix = {arXiv},
  eprint = {1811.00995},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Behrmann et al_2019_Invertible Residual Networks.pdf},
  journal = {arXiv:1811.00995 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{beitlerPIEPseudoInvertibleEncoder2018,
  title = {{{PIE}}: {{Pseudo}}-{{Invertible Encoder}}},
  shorttitle = {{{PIE}}},
  author = {Beitler, Jan Jetze and Sosnovik, Ivan and Smeulders, Arnold},
  year = {2018},
  month = sep,
  abstract = {New Class of Autoencoders with pseudo invertible architecture},
  file = {/home/selflein/Documents/Zotero/papers/Beitler et al_2018_PIE.pdf},
  language = {en}
}

@article{bilosUncertaintyAsynchronousTime2020,
  title = {Uncertainty on {{Asynchronous Time Event Prediction}}},
  author = {Bilo{\v s}, Marin and Charpentier, Bertrand and G{\"u}nnemann, Stephan},
  year = {2020},
  month = jan,
  abstract = {Asynchronous event sequences are the basis of many applications throughout different industries. In this work, we tackle the task of predicting the next event (given a history), and how this prediction changes with the passage of time. Since at some time points (e.g. predictions far into the future) we might not be able to predict anything with confidence, capturing uncertainty in the predictions is crucial. We present two new architectures, WGP-LN and FD-Dir, modelling the evolution of the distribution on the probability simplex with time-dependent logistic normal and Dirichlet distributions. In both cases, the combination of RNNs with either Gaussian process or function decomposition allows to express rich temporal evolution of the distribution parameters, and naturally captures uncertainty. Experiments on class prediction, time prediction and anomaly detection demonstrate the high performances of our models on various datasets compared to other approaches.},
  archiveprefix = {arXiv},
  eprint = {1911.05503},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Bilo≈° et al_2020_Uncertainty on Asynchronous Time Event Prediction.pdf},
  journal = {arXiv:1911.05503 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{bitterwolfCertifiablyAdversariallyRobust2021,
  title = {Certifiably {{Adversarially Robust Detection}} of {{Out}}-of-{{Distribution Data}}},
  author = {Bitterwolf, Julian and Meinke, Alexander and Hein, Matthias},
  year = {2021},
  month = mar,
  abstract = {Deep neural networks are known to be overconfident when applied to out-of-distribution (OOD) inputs which clearly do not belong to any class. This is a problem in safety-critical applications since a reliable assessment of the uncertainty of a classifier is a key property, allowing the system to trigger human intervention or to transfer into a safe state. In this paper, we aim for certifiable worst case guarantees for OOD detection by enforcing not only low confidence at the OOD point but also in an \$l\_\textbackslash infty\$-ball around it. For this purpose, we use interval bound propagation (IBP) to upper bound the maximal confidence in the \$l\_\textbackslash infty\$-ball and minimize this upper bound during training time. We show that non-trivial bounds on the confidence for OOD data generalizing beyond the OOD dataset seen at training time are possible. Moreover, in contrast to certified adversarial robustness which typically comes with significant loss in prediction performance, certified guarantees for worst case OOD detection are possible without much loss in accuracy.},
  archiveprefix = {arXiv},
  eprint = {2007.08473},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Bitterwolf et al_2021_Certifiably Adversarially Robust Detection of Out-of-Distribution Data.pdf},
  journal = {arXiv:2007.08473 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{blundellWeightUncertaintyNeural2015,
  title = {Weight {{Uncertainty}} in {{Neural Networks}}},
  author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  year = {2015},
  month = may,
  abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
  archiveprefix = {arXiv},
  eprint = {1505.05424},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Blundell et al_2015_Weight Uncertainty in Neural Networks.pdf},
  journal = {arXiv:1505.05424 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{brehmerFlowsSimultaneousManifold2020,
  title = {Flows for Simultaneous Manifold Learning and Density Estimation},
  author = {Brehmer, Johann and Cranmer, Kyle},
  year = {2020},
  month = nov,
  abstract = {We introduce manifold-learning flows (M-flows), a new class of generative models that simultaneously learn the data manifold as well as a tractable probability density on that manifold. Combining aspects of normalizing flows, GANs, autoencoders, and energy-based models, they have the potential to represent datasets with a manifold structure more faithfully and provide handles on dimensionality reduction, denoising, and out-of-distribution detection. We argue why such models should not be trained by maximum likelihood alone and present a new training algorithm that separates manifold and density updates. In a range of experiments we demonstrate how M-flows learn the data manifold and allow for better inference than standard flows in the ambient data space.},
  archiveprefix = {arXiv},
  eprint = {2003.13913},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Brehmer_Cranmer_2020_Flows for simultaneous manifold learning and density estimation.pdf},
  journal = {arXiv:2003.13913 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Normalizing Flow,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{brierVerificationForecastsExpressed1950,
  title = {Verification of {{Forecasts Expressed}} in {{Terms}} of {{Probability}}},
  author = {Brier, Glenn W.},
  year = {1950},
  volume = {78},
  pages = {1},
  issn = {0027-0644},
  doi = {10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
  abstract = {Not Available},
  file = {/home/selflein/Documents/Zotero/papers/Brier_1950_Verification of Forecasts Expressed in Terms of Probability.pdf},
  journal = {Monthly Weather Review}
}

@misc{bulatovMachineLearningEtc2011,
  title = {Machine {{Learning}}, Etc: {{notMNIST}} Dataset},
  shorttitle = {Machine {{Learning}}, Etc},
  author = {Bulatov, Yaroslav},
  year = {2011},
  month = sep,
  journal = {Machine Learning, etc}
}

@article{ceylanConditionalNoiseContrastiveEstimation2018,
  title = {Conditional {{Noise}}-{{Contrastive Estimation}} of {{Unnormalised Models}}},
  author = {Ceylan, Ciwan and Gutmann, Michael U.},
  year = {2018},
  month = jun,
  abstract = {Many parametric statistical models are not properly normalised and only specified up to an intractable partition function, which renders parameter estimation difficult. Examples of unnormalised models are Gibbs distributions, Markov random fields, and neural network models in unsupervised deep learning. In previous work, the estimation principle called noise-contrastive estimation (NCE) was introduced where unnormalised models are estimated by learning to distinguish between data and auxiliary noise. An open question is how to best choose the auxiliary noise distribution. We here propose a new method that addresses this issue. The proposed method shares with NCE the idea of formulating density estimation as a supervised learning problem but in contrast to NCE, the proposed method leverages the observed data when generating noise samples. The noise can thus be generated in a semi-automated manner. We first present the underlying theory of the new method, show that score matching emerges as a limiting case, validate the method on continuous and discrete valued synthetic data, and show that we can expect an improved performance compared to NCE when the data lie in a lower-dimensional manifold. Then we demonstrate its applicability in unsupervised deep learning by estimating a four-layer neural image model.},
  archiveprefix = {arXiv},
  eprint = {1806.03664},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ceylan_Gutmann_2018_Conditional Noise-Contrastive Estimation of Unnormalised Models.pdf},
  journal = {arXiv:1806.03664 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{charpentierNaturalPosteriorNetwork2021,
  title = {Natural {{Posterior Network}}: {{Deep Bayesian Predictive Uncertainty}} for {{Exponential Family Distributions}}},
  shorttitle = {Natural {{Posterior Network}}},
  author = {Charpentier, Bertrand and Borchert, Oliver and Z{\"u}gner, Daniel and Geisler, Simon and G{\"u}nnemann, Stephan},
  year = {2021},
  month = may,
  abstract = {Uncertainty awareness is crucial to develop reliable machine learning models. In this work, we propose the Natural Posterior Network (NatPN) for fast and highquality uncertainty estimation for any task where the target distribution belongs to the exponential family. Thus, NatPN finds application for both classification and general regression settings. Unlike many previous approaches, NatPN does not require out-of-distribution (OOD) data at training time. Instead, it leverages Normalizing Flows to fit a single density on a learned low-dimensional and taskdependent latent space. For any input sample, NatPN uses the predicted likelihood to perform a Bayesian update over the target distribution. Theoretically, NatPN assigns high uncertainty far away from training data. Empirically, our extensive experiments on calibration and OOD detection show that NatPN delivers highly competitive performance for classification, regression and count prediction tasks.},
  archiveprefix = {arXiv},
  eprint = {2105.04471},
  eprinttype = {arxiv},
  file = {/home/selflein/Zotero/storage/P7N8N32I/Charpentier et al. - 2021 - Natural Posterior Network Deep Bayesian Predictiv.pdf},
  journal = {arXiv:2105.04471 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@article{charpentierPosteriorNetworkUncertainty2020,
  title = {Posterior {{Network}}: {{Uncertainty Estimation}} without {{OOD Samples}} via {{Density}}-{{Based Pseudo}}-{{Counts}}},
  shorttitle = {Posterior {{Network}}},
  author = {Charpentier, Bertrand and Z{\"u}gner, Daniel and G{\"u}nnemann, Stephan},
  year = {2020},
  month = jun,
  abstract = {Accurate estimation of aleatoric and epistemic uncertainty is crucial to build safe and reliable systems. Traditional approaches, such as dropout and ensemble methods, estimate uncertainty by sampling probability predictions from different submodels, which leads to slow uncertainty estimation at inference time. Recent works address this drawback by directly predicting parameters of prior distributions over the probability predictions with a neural network. While this approach has demonstrated accurate uncertainty estimation, it requires defining arbitrary target parameters for in-distribution data and makes the unrealistic assumption that out-of-distribution (OOD) data is known at training time. In this work we propose the Posterior Network (PostNet), which uses Normalizing Flows to predict an individual closed-form posterior distribution over predicted probabilites for any input sample. The posterior distributions learned by PostNet accurately reflect uncertainty for in- and out-of-distribution data -- without requiring access to OOD data at training time. PostNet achieves state-of-the art results in OOD detection and in uncertainty calibration under dataset shifts.},
  archiveprefix = {arXiv},
  eprint = {2006.09239},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Charpentier et al_2020_Posterior Network.pdf},
  journal = {arXiv:2006.09239 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{choiWAICWhyGenerative2019,
  title = {{{WAIC}}, but {{Why}}? {{Generative Ensembles}} for {{Robust Anomaly Detection}}},
  shorttitle = {{{WAIC}}, but {{Why}}?},
  author = {Choi, Hyunsun and Jang, Eric and Alemi, Alexander A.},
  year = {2019},
  month = may,
  abstract = {Machine learning models encounter Out-of-Distribution (OoD) errors when the data seen at test time are generated from a different stochastic generator than the one used to generate the training data. One proposal to scale OoD detection to high-dimensional data is to learn a tractable likelihood approximation of the training distribution, and use it to reject unlikely inputs. However, likelihood models on natural data are themselves susceptible to OoD errors, and even assign large likelihoods to samples from other datasets. To mitigate this problem, we propose Generative Ensembles, which robustify density-based OoD detection by way of estimating epistemic uncertainty of the likelihood model. We present a puzzling observation in need of an explanation -- although likelihood measures cannot account for the typical set of a distribution, and therefore should not be suitable on their own for OoD detection, WAIC performs surprisingly well in practice.},
  archiveprefix = {arXiv},
  eprint = {1810.01392},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Choi et al_2019_WAIC, but Why.pdf},
  journal = {arXiv:1810.01392 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@misc{clanuwat2018deep,
  title = {Deep Learning for Classical Japanese Literature},
  author = {Clanuwat, Tarin and {Bober-Irizar}, Mikel and Kitamoto, Asanobu and Lamb, Alex and Yamamoto, Kazuaki and Ha, David},
  year = {2018},
  month = dec,
  archiveprefix = {arXiv},
  eprint = {1812.01718},
  eprinttype = {arxiv},
  primaryclass = {cs.CV}
}

@article{clanuwatDeepLearningClassical2018,
  title = {Deep {{Learning}} for {{Classical Japanese Literature}}},
  author = {Clanuwat, Tarin and {Bober-Irizar}, Mikel and Kitamoto, Asanobu and Lamb, Alex and Yamamoto, Kazuaki and Ha, David},
  year = {2018},
  doi = {10.20676/00000341},
  abstract = {Much of machine learning research focuses on producing models which perform well on benchmark tasks, in turn improving our understanding of the challenges associated with those tasks. From the perspective of ML researchers, the content of the task itself is largely irrelevant, and thus there have increasingly been calls for benchmark tasks to more heavily focus on problems which are of social or cultural relevance. In this work, we introduce Kuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as well as two larger, more challenging datasets, Kuzushiji-49 and Kuzushiji-Kanji. Through these datasets, we wish to engage the machine learning community into the world of classical Japanese literature. Dataset available at https://github.com/rois-codh/kmnist},
  archiveprefix = {arXiv},
  eprint = {1812.01718},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Clanuwat et al_9999_Deep Learning for Classical Japanese Literature2.pdf},
  journal = {arXiv:1812.01718 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{clanuwatDeepLearningClassical9999,
  title = {Deep {{Learning}} for {{Classical Japanese Literature}}},
  author = {Clanuwat, Tarin and {Bober-Irizar}, Mikel and Kitamoto, Asanobu and Lamb, Alex and Yamamoto, Kazuaki and Ha, David},
  year = {9999},
  doi = {10.20676/00000341},
  abstract = {Much of machine learning research focuses on producing models which perform well on benchmark tasks, in turn improving our understanding of the challenges associated with those tasks. From the perspective of ML researchers, the content of the task itself is largely irrelevant, and thus there have increasingly been calls for benchmark tasks to more heavily focus on problems which are of social or cultural relevance. In this work, we introduce Kuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as well as two larger, more challenging datasets, Kuzushiji-49 and Kuzushiji-Kanji. Through these datasets, we wish to engage the machine learning community into the world of classical Japanese literature. Dataset available at https://github.com/rois-codh/kmnist},
  archiveprefix = {arXiv},
  eprint = {1812.01718},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Clanuwat et al_9999_Deep Learning for Classical Japanese Literature.pdf},
  journal = {arXiv:1812.01718 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{cunninghamNormalizingFlowsDimensions2020,
  title = {Normalizing {{Flows Across Dimensions}}},
  author = {Cunningham, Edmond and Zabounidis, Renos and Agrawal, Abhinav and Fiterau, Ina and Sheldon, Daniel},
  year = {2020},
  month = jun,
  abstract = {Real-world data with underlying structure, such as pictures of faces, are hypothesized to lie on a low-dimensional manifold. This manifold hypothesis has motivated state-of-the-art generative algorithms that learn low-dimensional data representations. Unfortunately, a popular generative model, normalizing flows, cannot take advantage of this. Normalizing flows are based on successive variable transformations that are, by design, incapable of learning lower-dimensional representations. In this paper we introduce noisy injective flows (NIF), a generalization of normalizing flows that can go across dimensions. NIF explicitly map the latent space to a learnable manifold in a high-dimensional data space using injective transformations. We further employ an additive noise model to account for deviations from the manifold and identify a stochastic inverse of the generative process. Empirically, we demonstrate that a simple application of our method to existing flow architectures can significantly improve sample quality and yield separable data embeddings.},
  archiveprefix = {arXiv},
  eprint = {2006.13070},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Cunningham et al_2020_Normalizing Flows Across Dimensions.pdf},
  journal = {arXiv:2006.13070 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@inproceedings{davisRelationshipPrecisionRecallROC2006,
  title = {The Relationship between {{Precision}}-{{Recall}} and {{ROC}} Curves},
  booktitle = {Proceedings of the 23rd International Conference on {{Machine}} Learning},
  author = {Davis, Jesse and Goadrich, Mark},
  year = {2006},
  month = jun,
  pages = {233--240},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1143844.1143874},
  abstract = {Receiver Operator Characteristic (ROC) curves are commonly used to present results for binary decision problems in machine learning. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. We show that a deep connection exists between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. A corollary is the notion of an achievable PR curve, which has properties much like the convex hull in ROC space; we show an efficient algorithm for computing this curve. Finally, we also note differences in the two types of curves are significant for algorithm design. For example, in PR space it is incorrect to linearly interpolate between points. Furthermore, algorithms that optimize the area under the ROC curve are not guaranteed to optimize the area under the PR curve.},
  file = {/home/selflein/Documents/Zotero/papers/Davis_Goadrich_2006_The relationship between Precision-Recall and ROC curves.pdf},
  isbn = {978-1-59593-383-6},
  series = {{{ICML}} '06}
}

@article{devriesLearningConfidenceOutofDistribution2018,
  title = {Learning {{Confidence}} for {{Out}}-of-{{Distribution Detection}} in {{Neural Networks}}},
  author = {DeVries, Terrance and Taylor, Graham W.},
  year = {2018},
  month = feb,
  abstract = {Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.},
  archiveprefix = {arXiv},
  eprint = {1802.04865},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/DeVries_Taylor_2018_Learning Confidence for Out-of-Distribution Detection in Neural Networks.pdf},
  journal = {arXiv:1802.04865 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{diengPrescribedGenerativeAdversarial2019,
  title = {Prescribed {{Generative Adversarial Networks}}},
  author = {Dieng, Adji B. and Ruiz, Francisco J. R. and Blei, David M. and Titsias, Michalis K.},
  year = {2019},
  month = oct,
  abstract = {Generative adversarial networks (GANs) are a powerful approach to unsupervised learning. They have achieved state-of-the-art performance in the image domain. However, GANs are limited in two ways. They often learn distributions with low support---a phenomenon known as mode collapse---and they do not guarantee the existence of a probability density, which makes evaluating generalization using predictive log-likelihood impossible. In this paper, we develop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs add noise to the output of a density network and optimize an entropy-regularized adversarial loss. The added noise renders tractable approximations of the predictive log-likelihood and stabilizes the training procedure. The entropy regularizer encourages PresGANs to capture all the modes of the data distribution. Fitting PresGANs involves computing the intractable gradients of the entropy regularization term; PresGANs sidestep this intractability using unbiased stochastic estimates. We evaluate PresGANs on several datasets and found they mitigate mode collapse and generate samples with high perceptual quality. We further found that PresGANs reduce the gap in performance in terms of predictive log-likelihood between traditional GANs and variational autoencoders (VAEs).},
  archiveprefix = {arXiv},
  eprint = {1910.04302},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Dieng et al_2019_Prescribed Generative Adversarial Networks.pdf},
  journal = {arXiv:1910.04302 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryclass = {cs, stat}
}

@article{dinhDensityEstimationUsing2017,
  title = {Density Estimation Using {{Real NVP}}},
  author = {Dinh, Laurent and {Sohl-Dickstein}, Jascha and Bengio, Samy},
  year = {2017},
  month = feb,
  abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
  archiveprefix = {arXiv},
  eprint = {1605.08803},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Dinh et al_2017_Density estimation using Real NVP.pdf},
  journal = {arXiv:1605.08803 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{Dua:2019,
  title = {{{UCI}} Machine Learning Repository},
  author = {Dua, Dheeru and Graff, Casey},
  year = {2017},
  publisher = {{University of California, Irvine, School of Information and Computer Sciences}}
}

@article{duImplicitGenerationGeneralization2020b,
  title = {Implicit {{Generation}} and {{Generalization}} in {{Energy}}-{{Based Models}}},
  author = {Du, Yilun and Mordatch, Igor},
  year = {2020},
  month = jun,
  abstract = {Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.},
  archiveprefix = {arXiv},
  eprint = {1903.08689},
  eprinttype = {arxiv},
  file = {/home/selflein/Zotero/storage/T38N3C2P/Du and Mordatch - 2020 - Implicit Generation and Generalization in Energy-B.pdf},
  journal = {arXiv:1903.08689 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@article{duImprovedContrastiveDivergence2021,
  title = {Improved {{Contrastive Divergence Training}} of {{Energy Based Models}}},
  author = {Du, Yilun and Li, Shuang and Tenenbaum, Joshua and Mordatch, Igor},
  year = {2021},
  month = apr,
  abstract = {Contrastive divergence is a popular method of training energy-based models, but is known to have difficulties with training stability. We propose an adaptation to improve contrastive divergence training by scrutinizing a gradient term that is difficult to calculate and is often left out for convenience. We show that this gradient term is numerically significant and in practice is important to avoid training instabilities, while being tractable to estimate. We further highlight how data augmentation and multi-scale processing can be used to improve model robustness and generation quality. Finally, we empirically evaluate stability of model architectures and show improved performance on a host of benchmarks and use cases,such as image generation, OOD detection, and compositional generation.},
  archiveprefix = {arXiv},
  eprint = {2012.01316},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Du et al_2021_Improved Contrastive Divergence Training of Energy Based Models.pdf},
  journal = {arXiv:2012.01316 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{durkanContrastiveLearningLikelihoodfree2020,
  title = {On {{Contrastive Learning}} for {{Likelihood}}-Free {{Inference}}},
  author = {Durkan, Conor and Murray, Iain and Papamakarios, George},
  year = {2020},
  month = dec,
  abstract = {Likelihood-free methods perform parameter inference in stochastic simulator models where evaluating the likelihood is intractable but sampling synthetic data is possible. One class of methods for this likelihood-free problem uses a classifier to distinguish between pairs of parameter-observation samples generated using the simulator and pairs sampled from some reference distribution, which implicitly learns a density ratio proportional to the likelihood. Another popular class of methods fits a conditional distribution to the parameter posterior directly, and a particular recent variant allows for the use of flexible neural density estimators for this task. In this work, we show that both of these approaches can be unified under a general contrastive learning scheme, and clarify how they should be run and compared.},
  archiveprefix = {arXiv},
  eprint = {2002.03712},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Durkan et al_2020_On Contrastive Learning for Likelihood-free Inference.pdf},
  journal = {arXiv:2002.03712 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@book{erdilUnsupervisedOutofdistributionDetection2020,
  title = {Unsupervised Out-of-Distribution Detection Using Kernel Density Estimation},
  author = {Erdil, Ertunc and Chaitanya, Krishna and Konukoglu, Ender},
  year = {2020},
  month = jun,
  abstract = {Deep neural networks achieve significant advancement to the state-of-the-art in many computer vision tasks. However, accuracy of the networks may drop drastically when test data come from a different distribution than training data. Therefore, detecting out-of-distribution (OOD) examples in neural networks arises as a crucial problem. Although, majority of the existing methods focuses on OOD detection in classification networks, the problem exist for any type of networks. In this paper, we propose an unsupervised OOD detection method that can work with both classification and non-classification networks by using kernel density estimation (KDE). The proposed method estimates probability density functions (pdfs) of activations at various levels of the network by performing KDE on the in-distribution dataset. At test time, the pdfs are evaluated on the test data to obtain a confidence score for each layer which are expected to be higher for in-distribution and lower for OOD. The scores are combined into a final score using logistic regression. We perform experiments on 2 different classification networks trained on CIFAR-10 and CIFAR-100, and on a segmentation network trained on Pascal VOC datasets. In CIFAR-10, our method achieves better results than the other methods in 4 of 6 OOD datasets while being the second best in the remaining ones. In CIFAR-100, we obtain the best results in 2 and the second best in 3 OOD datasets. In the segmentation network, we achieve the highest scores according to most of the evaluation metrics among all other OOD detection methods. The results demonstrate that the proposed method achieves competitive results to the state-of-the-art in classification networks and leads to improvement on segmentation network.},
  file = {/home/selflein/Documents/Zotero/papers/Erdil et al_2020_Unsupervised out-of-distribution detection using kernel density estimation.pdf}
}

@article{feffermanTestingManifoldHypothesis2013,
  title = {Testing the {{Manifold Hypothesis}}},
  author = {Fefferman, Charles and Mitter, Sanjoy and Narayanan, Hariharan},
  year = {2013},
  month = dec,
  abstract = {The hypothesis that high dimensional data tend to lie in the vicinity of a low dimensional manifold is the basis of manifold learning. The goal of this paper is to develop an algorithm (with accompanying complexity guarantees) for fitting a manifold to an unknown probability distribution supported in a separable Hilbert space, only using i.i.d samples from that distribution. More precisely, our setting is the following. Suppose that data are drawn independently at random from a probability distribution \$P\$ supported on the unit ball of a separable Hilbert space \$H\$. Let \$G(d, V, \textbackslash tau)\$ be the set of submanifolds of the unit ball of \$H\$ whose volume is at most \$V\$ and reach (which is the supremum of all \$r\$ such that any point at a distance less than \$r\$ has a unique nearest point on the manifold) is at least \$\textbackslash tau\$. Let \$L(M, P)\$ denote mean-squared distance of a random point from the probability distribution \$P\$ to \$M\$. We obtain an algorithm that tests the manifold hypothesis in the following sense. The algorithm takes i.i.d random samples from \$P\$ as input, and determines which of the following two is true (at least one must be): (a) There exists \$M \textbackslash in G(d, CV, \textbackslash frac\{\textbackslash tau\}\{C\})\$ such that \$L(M, P) \textbackslash leq C \textbackslash epsilon.\$ (b) There exists no \$M \textbackslash in G(d, V/C, C\textbackslash tau)\$ such that \$L(M, P) \textbackslash leq \textbackslash frac\{\textbackslash epsilon\}\{C\}.\$ The answer is correct with probability at least \$1-\textbackslash delta\$.},
  archiveprefix = {arXiv},
  eprint = {1310.0425},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Fefferman et al_2013_Testing the Manifold Hypothesis.pdf},
  journal = {arXiv:1310.0425 [math, stat]},
  keywords = {62G08,Mathematics - Classical Analysis and ODEs,Mathematics - Differential Geometry,Mathematics - Statistics Theory},
  primaryclass = {math, stat}
}

@article{galDropoutBayesianApproximation2016,
  title = {Dropout as a {{Bayesian Approximation}}: {{Representing Model Uncertainty}} in {{Deep Learning}}},
  shorttitle = {Dropout as a {{Bayesian Approximation}}},
  author = {Gal, Yarin and Ghahramani, Zoubin},
  year = {2016},
  month = oct,
  abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
  archiveprefix = {arXiv},
  eprint = {1506.02142},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Gal_Ghahramani_2016_Dropout as a Bayesian Approximation.pdf},
  journal = {arXiv:1506.02142 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Uncertainty Estimation},
  primaryclass = {cs, stat}
}

@article{gaoFlowContrastiveEstimation2020,
  title = {Flow {{Contrastive Estimation}} of {{Energy}}-{{Based Models}}},
  author = {Gao, Ruiqi and Nijkamp, Erik and Kingma, Diederik P. and Xu, Zhen and Dai, Andrew M. and Wu, Ying Nian},
  year = {2020},
  month = apr,
  abstract = {This paper studies a training method to jointly estimate an energy-based model and a flow-based model, in which the two models are iteratively updated based on a shared adversarial value function. This joint training method has the following traits. (1) The update of the energy-based model is based on noise contrastive estimation, with the flow model serving as a strong noise distribution. (2) The update of the flow model approximately minimizes the Jensen-Shannon divergence between the flow model and the data distribution. (3) Unlike generative adversarial networks (GAN) which estimates an implicit probability distribution defined by a generator model, our method estimates two explicit probabilistic distributions on the data. Using the proposed method we demonstrate a significant improvement on the synthesis quality of the flow model, and show the effectiveness of unsupervised feature learning by the learned energy-based model. Furthermore, the proposed training method can be easily adapted to semi-supervised learning. We achieve competitive results to the state-of-the-art semi-supervised learning methods.},
  archiveprefix = {arXiv},
  eprint = {1912.00589},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Gao et al_2020_Flow Contrastive Estimation of Energy-Based Models.pdf},
  journal = {arXiv:1912.00589 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{gaoLearningEnergyBasedModels2020,
  title = {Learning {{Energy}}-{{Based Models}} by {{Diffusion Recovery Likelihood}}},
  author = {Gao, Ruiqi and Song, Yang and Poole, Ben and Wu, Ying Nian and Kingma, Diederik P.},
  year = {2020},
  month = dec,
  abstract = {While energy-based models (EBMs) exhibit a number of desirable properties, training and sampling on high-dimensional datasets remains challenging. Inspired by recent progress on diffusion probabilistic models, we present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM is trained by maximizing the recovery likelihood: the conditional probability of the data at a certain noise level given their noisy versions at a higher noise level. The recovery likelihood objective is more tractable than the marginal likelihood objective, since it only requires MCMC sampling from a relatively concentrated conditional distribution. Moreover, we show that this estimation method is theoretically consistent: it learns the correct conditional and marginal distributions at each noise level, given sufficient data. After training, synthesized images can be generated efficiently by a sampling process that initializes from a spherical Gaussian distribution and progressively samples the conditional distributions at decreasingly lower noise levels. Our method generates high fidelity samples on various image datasets. On unconditional CIFAR-10 our method achieves FID 9.60 and inception score 8.58, superior to the majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our long-run MCMC samples from the conditional distributions do not diverge and still represent realistic images, allowing us to accurately estimate the normalized density of data even for high-dimensional datasets.},
  archiveprefix = {arXiv},
  eprint = {2012.08125},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Gao et al_2020_Learning Energy-Based Models by Diffusion Recovery Likelihood.pdf},
  journal = {arXiv:2012.08125 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{germainMADEMaskedAutoencoder2015,
  title = {{{MADE}}: {{Masked Autoencoder}} for {{Distribution Estimation}}},
  shorttitle = {{{MADE}}},
  author = {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
  year = {2015},
  month = jun,
  abstract = {There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder's parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with state-of-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.},
  archiveprefix = {arXiv},
  eprint = {1502.03509},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Germain et al_2015_MADE.pdf},
  journal = {arXiv:1502.03509 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{grathwohlLearningSteinDiscrepancy2020,
  title = {Learning the {{Stein Discrepancy}} for {{Training}} and {{Evaluating Energy}}-{{Based Models}} without {{Sampling}}},
  author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Jorn-Henrik and Duvenaud, David and Zemel, Richard},
  year = {2020},
  month = aug,
  abstract = {We present a new method for evaluating and training unnormalized density models. Our approach only requires access to the gradient of the unnormalized model's log-density. We estimate the Stein discrepancy between the data density \$p(x)\$ and the model density \$q(x)\$ defined by a vector function of the data. We parameterize this function with a neural network and fit its parameters to maximize the discrepancy. This yields a novel goodness-of-fit test which outperforms existing methods on high dimensional data. Furthermore, optimizing \$q(x)\$ to minimize this discrepancy produces a novel method for training unnormalized models which scales more gracefully than existing methods. The ability to both learn and compare models is a unique feature of the proposed method.},
  archiveprefix = {arXiv},
  eprint = {2002.05616},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Grathwohl et al_2020_Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models.pdf},
  journal = {arXiv:2002.05616 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{grathwohlNoMCMCMe2020,
  title = {No {{MCMC}} for Me: {{Amortized}} Sampling for Fast and Stable Training of Energy-Based Models},
  shorttitle = {No {{MCMC}} for Me},
  author = {Grathwohl, Will and Kelly, Jacob and Hashemi, Milad and Norouzi, Mohammad and Swersky, Kevin and Duvenaud, David},
  year = {2020},
  month = oct,
  abstract = {Energy-Based Models (EBMs) present a flexible and appealing way to represent uncertainty. Despite recent advances, training EBMs on high-dimensional data remains a challenging problem as the state-of-the-art approaches are costly, unstable, and require considerable tuning and domain expertise to apply successfully. In this work, we present a simple method for training EBMs at scale which uses an entropy-regularized generator to amortize the MCMC sampling typically used in EBM training. We improve upon prior MCMC-based entropy regularization methods with a fast variational approximation. We demonstrate the effectiveness of our approach by using it to train tractable likelihood models. Next, we apply our estimator to the recently proposed Joint Energy Model (JEM), where we match the original performance with faster and stable training. This allows us to extend JEM models to semi-supervised classification on tabular data from a variety of continuous domains.},
  archiveprefix = {arXiv},
  eprint = {2010.04230},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Grathwohl et al. - 2020 - No MCMC for me Amortized sampling for fast and st.pdf},
  journal = {arXiv:2010.04230 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{grathwohlOopsTookGradient2021,
  title = {Oops {{I Took A Gradient}}: {{Scalable Sampling}} for {{Discrete Distributions}}},
  shorttitle = {Oops {{I Took A Gradient}}},
  author = {Grathwohl, Will and Swersky, Kevin and Hashemi, Milad and Duvenaud, David and Maddison, Chris J.},
  year = {2021},
  month = feb,
  abstract = {We propose a general and scalable approximate sampling strategy for probabilistic models with discrete variables. Our approach uses gradients of the likelihood function with respect to its discrete inputs to propose updates in a Metropolis-Hastings sampler. We show empirically that this approach outperforms generic samplers in a number of difficult settings including Ising models, Potts models, restricted Boltzmann machines, and factorial hidden Markov models. We also demonstrate the use of our improved sampler for training deep energy-based models on high dimensional discrete data. This approach outperforms variational auto-encoders and existing energy-based models. Finally, we give bounds showing that our approach is near-optimal in the class of samplers which propose local updates.},
  archiveprefix = {arXiv},
  eprint = {2102.04509},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Grathwohl et al_2021_Oops I Took A Gradient.pdf},
  journal = {arXiv:2102.04509 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{grathwohlYourClassifierSecretly2020,
  title = {Your {{Classifier}} Is {{Secretly}} an {{Energy Based Model}} and {{You Should Treat}} It {{Like One}}},
  author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, J{\"o}rn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
  year = {2020},
  month = sep,
  abstract = {We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model.},
  archiveprefix = {arXiv},
  eprint = {1912.03263},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Grathwohl et al_2020_Your Classifier is Secretly an Energy Based Model and You Should Treat it Like_annotated.pdf;/home/selflein/Documents/Zotero/papers/Grathwohl et al_2020_Your Classifier is Secretly an Energy Based Model and You Should Treat it Like.pdf},
  journal = {arXiv:1912.03263 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{gutmannNoisecontrastiveEstimationNew,
  title = {Noise-Contrastive Estimation: {{A}} New Estimation Principle for Unnormalized Statistical Models},
  author = {Gutmann, Michael and Hyvarinen, Aapo},
  pages = {8},
  abstract = {We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity. We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance. In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.},
  file = {/home/selflein/Zotero/storage/ME2ACEKI/Gutmann and Hyvarinen - Noise-contrastive estimation A new estimation pri.pdf},
  language = {en}
}

@article{heinWhyReLUNetworks2019,
  title = {Why {{ReLU}} Networks Yield High-Confidence Predictions Far Away from the Training Data and How to Mitigate the Problem},
  author = {Hein, Matthias and Andriushchenko, Maksym and Bitterwolf, Julian},
  year = {2019},
  month = may,
  abstract = {Classifiers used in the wild, in particular for safety-critical systems, should not only have good generalization properties but also should know when they don't know, in particular make low confidence predictions far away from the training data. We show that ReLU type neural networks which yield a piecewise linear classifier function fail in this regard as they produce almost always high confidence predictions far away from the training data. For bounded domains like images we propose a new robust optimization technique similar to adversarial training which enforces low confidence predictions far away from the training data. We show that this technique is surprisingly effective in reducing the confidence of predictions far away from the training data while maintaining high confidence predictions and test error on the original classification task compared to standard training.},
  archiveprefix = {arXiv},
  eprint = {1812.05720},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hein et al_2019_Why ReLU networks yield high-confidence predictions far away from the training.pdf},
  journal = {arXiv:1812.05720 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{hendrycksBaselineDetectingMisclassified2018,
  title = {A {{Baseline}} for {{Detecting Misclassified}} and {{Out}}-of-{{Distribution Examples}} in {{Neural Networks}}},
  author = {Hendrycks, Dan and Gimpel, Kevin},
  year = {2018},
  month = oct,
  abstract = {We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.},
  archiveprefix = {arXiv},
  eprint = {1610.02136},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hendrycks_Gimpel_2018_A Baseline for Detecting Misclassified and Out-of-Distribution Examples in.pdf},
  journal = {arXiv:1610.02136 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryclass = {cs}
}

@article{hendrycksBenchmarkingNeuralNetwork2019,
  title = {Benchmarking {{Neural Network Robustness}} to {{Common Corruptions}} and {{Perturbations}}},
  author = {Hendrycks, Dan and Dietterich, Thomas},
  year = {2019},
  month = mar,
  abstract = {In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.},
  archiveprefix = {arXiv},
  eprint = {1903.12261},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hendrycks_Dietterich_2019_Benchmarking Neural Network Robustness to Common Corruptions and Perturbations.pdf},
  journal = {arXiv:1903.12261 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{hendrycksDeepAnomalyDetection2019,
  title = {Deep {{Anomaly Detection}} with {{Outlier Exposure}}},
  author = {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  year = {2019},
  month = jan,
  abstract = {It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.},
  archiveprefix = {arXiv},
  eprint = {1812.04606},
  eprinttype = {arxiv},
  file = {/home/selflein/Zotero/storage/YPLJZK9B/Hendrycks et al. - 2019 - Deep Anomaly Detection with Outlier Exposure.pdf},
  journal = {arXiv:1812.04606 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@article{hendrycksDeepAnomalyDetection2019a,
  title = {Deep {{Anomaly Detection}} with {{Outlier Exposure}}},
  author = {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  year = {2019},
  month = jan,
  abstract = {It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.},
  archiveprefix = {arXiv},
  eprint = {1812.04606},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hendrycks et al_2019_Deep Anomaly Detection with Outlier Exposure2.pdf},
  journal = {arXiv:1812.04606 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{hendrycksUsingSelfSupervisedLearning2019,
  title = {Using {{Self}}-{{Supervised Learning Can Improve Model Robustness}} and {{Uncertainty}}},
  author = {Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
  year = {2019},
  month = oct,
  abstract = {Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating or reducing the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research.},
  archiveprefix = {arXiv},
  eprint = {1906.12340},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hendrycks et al_2019_Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty.pdf},
  journal = {arXiv:1906.12340 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{hendrycksUsingSelfSupervisedLearning2019a,
  title = {Using {{Self}}-{{Supervised Learning Can Improve Model Robustness}} and {{Uncertainty}}},
  author = {Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
  year = {2019},
  month = oct,
  abstract = {Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating or reducing the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research.},
  archiveprefix = {arXiv},
  eprint = {1906.12340},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hendrycks et al_2019_Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty2.pdf},
  journal = {arXiv:1906.12340 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{hintonTrainingProductsExperts2002,
  title = {Training {{Products}} of {{Experts}} by {{Minimizing Contrastive Divergence}}},
  author = {Hinton, Geoffrey E.},
  year = {2002},
  month = aug,
  volume = {14},
  pages = {1771--1800},
  issn = {0899-7667},
  doi = {10.1162/089976602760128018},
  abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual ``expert'' models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called ``contrastive divergence'' whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
  journal = {Neural Computation},
  number = {8}
}

@article{hsuGeneralizedODINDetecting2020,
  title = {Generalized {{ODIN}}: {{Detecting Out}}-of-Distribution {{Image}} without {{Learning}} from {{Out}}-of-Distribution {{Data}}},
  shorttitle = {Generalized {{ODIN}}},
  author = {Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia and Kira, Zsolt},
  year = {2020},
  month = mar,
  abstract = {Deep neural networks have attained remarkable performance when applied to data that comes from the same distribution as that of the training set, but can significantly degrade otherwise. Therefore, detecting whether an example is out-of-distribution (OoD) is crucial to enable a system that can reject such samples or alert users. Recent works have made significant progress on OoD benchmarks consisting of small image datasets. However, many recent methods based on neural networks rely on training or tuning with both in-distribution and out-of-distribution data. The latter is generally hard to define a-priori, and its selection can easily bias the learning. We base our work on a popular method ODIN, proposing two strategies for freeing it from the needs of tuning with OoD data, while improving its OoD detection performance. We specifically propose to decompose confidence scoring as well as a modified input pre-processing method. We show that both of these significantly help in detection performance. Our further analysis on a larger scale image dataset shows that the two types of distribution shifts, specifically semantic shift and non-semantic shift, present a significant difference in the difficulty of the problem, providing an analysis of when ODIN-like strategies do or do not work.},
  archiveprefix = {arXiv},
  eprint = {2002.11297},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Hsu et al_2020_Generalized ODIN.pdf},
  journal = {arXiv:2002.11297 [cs, eess]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  primaryclass = {cs, eess}
}

@article{huangCompactConvolutionalNeural2020,
  title = {A {{Compact Convolutional Neural Network}} for {{Surface Defect Inspection}}},
  author = {Huang, Yibin and Qiu, C. and Wang, X. and Wang, Shijun and Yuan, Kui},
  year = {2020},
  doi = {10.3390/s20071974},
  abstract = {The advent of convolutional neural networks (CNNs) has accelerated the progress of computer vision from many aspects. However, the majority of the existing CNNs heavily rely on expensive GPUs (graphics processing units). to support large computations. Therefore, CNNs have not been widely used to inspect surface defects in the manufacturing field yet. In this paper, we develop a compact CNN-based model that not only achieves high performance on tiny defect inspection but can be run on low-frequency CPUs (central processing units). Our model consists of a light-weight (LW) bottleneck and a decoder. By a pyramid of lightweight kernels, the LW bottleneck provides rich features with less computational cost. The decoder is also built in a lightweight way, which consists of an atrous spatial pyramid pooling (ASPP) and depthwise separable convolution layers. These lightweight designs reduce the redundant weights and computation greatly. We train our models on groups of surface datasets. The model can successfully classify/segment surface defects with an Intel i3-4010U CPU within 30 ms. Our model obtains similar accuracy with MobileNetV2 while only has less than its 1/3 FLOPs (floating-point operations per second) and 1/8 weights. Our experiments indicate CNNs can be compact and hardware-friendly for future applications in the automated surface inspection (ASI).},
  file = {/home/selflein/Documents/Zotero/papers/Huang et al_2020_A Compact Convolutional Neural Network for Surface Defect Inspection.pdf},
  journal = {Sensors}
}

@article{hyvarinenEstimationNonNormalizedStatistical2005,
  title = {Estimation of {{Non}}-{{Normalized Statistical Models}} by {{Score Matching}}},
  author = {Hyv{\"a}rinen, Aapo},
  year = {2005},
  month = dec,
  volume = {6},
  pages = {695--709},
  issn = {1532-4435},
  abstract = {One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very difficult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simplifies to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete filter set for natural image data.},
  journal = {The Journal of Machine Learning Research}
}

@article{jangCategoricalReparameterizationGumbelSoftmax2017,
  title = {Categorical {{Reparameterization}} with {{Gumbel}}-{{Softmax}}},
  author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  year = {2017},
  month = aug,
  abstract = {Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.},
  archiveprefix = {arXiv},
  eprint = {1611.01144},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Jang et al_2017_Categorical Reparameterization with Gumbel-Softmax.pdf},
  journal = {arXiv:1611.01144 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{kingmaAutoEncodingVariationalBayes2014,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, M.},
  year = {2014},
  abstract = {Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  file = {/home/selflein/Documents/Zotero/papers/Kingma_Welling_2014_Auto-Encoding Variational Bayes.pdf},
  journal = {ICLR}
}

@article{kingmaGlowGenerativeFlow2018,
  title = {Glow: {{Generative Flow}} with {{Invertible}} 1x1 {{Convolutions}}},
  shorttitle = {Glow},
  author = {Kingma, Diederik P. and Dhariwal, Prafulla},
  year = {2018},
  month = jul,
  abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
  archiveprefix = {arXiv},
  eprint = {1807.03039},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Kingma_Dhariwal_2018_Glow.pdf},
  journal = {arXiv:1807.03039 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{kirichenkoWhyNormalizingFlows2020,
  title = {Why {{Normalizing Flows Fail}} to {{Detect Out}}-of-{{Distribution Data}}},
  author = {Kirichenko, Polina and Izmailov, Pavel and Wilson, Andrew Gordon},
  year = {2020},
  month = jun,
  abstract = {Detecting out-of-distribution (OOD) data is crucial for robust machine learning systems. Normalizing flows are flexible deep generative models that often surprisingly fail to distinguish between in- and out-of-distribution data: a flow trained on pictures of clothing assigns higher likelihood to handwritten digits. We investigate why normalizing flows perform poorly for OOD detection. We demonstrate that flows learn local pixel correlations and generic image-to-latent-space transformations which are not specific to the target image dataset. We show that by modifying the architecture of flow coupling layers we can bias the flow towards learning the semantic structure of the target data, improving OOD detection. Our investigation reveals that properties that enable flows to generate high-fidelity images can have a detrimental effect on OOD detection.},
  archiveprefix = {arXiv},
  eprint = {2006.08545},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Kirichenko et al_2020_Why Normalizing Flows Fail to Detect Out-of-Distribution Data.pdf},
  journal = {arXiv:2006.08545 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@misc{krizhevskyLearningMultipleLayers2009,
  title = {Learning {{Multiple Layers}} of {{Features}} from {{Tiny Images}}},
  author = {Krizhevsky, A.},
  year = {2009},
  abstract = {Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.},
  howpublished = {/paper/Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky/5d90f06bb70a0a3dced62413346235c02b1aa086},
  language = {en}
}

@article{kumarRegularizedAutoencodersRelaxed2020,
  title = {Regularized {{Autoencoders}} via {{Relaxed Injective Probability Flow}}},
  author = {Kumar, Abhishek and Poole, Ben and Murphy, Kevin},
  year = {2020},
  month = feb,
  abstract = {Invertible flow-based generative models are an effective method for learning to generate samples, while allowing for tractable likelihood computation and inference. However, the invertibility requirement restricts models to have the same latent dimensionality as the inputs. This imposes significant architectural, memory, and computational costs, making them more challenging to scale than other classes of generative models such as Variational Autoencoders (VAEs). We propose a generative model based on probability flows that does away with the bijectivity requirement on the model and only assumes injectivity. This also provides another perspective on regularized autoencoders (RAEs), with our final objectives resembling RAEs with specific regularizers that are derived by lower bounding the probability flow objective. We empirically demonstrate the promise of the proposed model, improving over VAEs and AEs in terms of sample quality.},
  archiveprefix = {arXiv},
  eprint = {2002.08927},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Kumar et al_2020_Regularized Autoencoders via Relaxed Injective Probability Flow.pdf},
  journal = {arXiv:2002.08927 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{lakshminarayananSimpleScalablePredictive2017,
  title = {Simple and {{Scalable Predictive Uncertainty Estimation}} Using {{Deep Ensembles}}},
  author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  year = {2017},
  month = nov,
  abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
  archiveprefix = {arXiv},
  eprint = {1612.01474},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Lakshminarayanan et al_2017_Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles.pdf},
  journal = {arXiv:1612.01474 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Uncertainty Estimation},
  primaryclass = {cs, stat}
}

@article{lanPerfectDensityModels2021,
  title = {Perfect Density Models Cannot Guarantee Anomaly Detection},
  author = {Lan, Charline Le and Dinh, Laurent},
  year = {2021},
  month = feb,
  abstract = {Thanks to the tractability of their likelihood, some deep generative models show promise for seemingly straightforward but important applications like anomaly detection, uncertainty estimation, and active learning. However, the likelihood values empirically attributed to anomalies conflict with the expectations these proposed applications suggest. In this paper, we take a closer look at the behavior of distribution densities and show that these quantities carry less meaningful information than previously thought, beyond estimation issues or the curse of dimensionality. We conclude that the use of these likelihoods for out-of-distribution detection relies on strong and implicit hypotheses, and highlight the necessity of explicitly formulating these assumptions for reliable anomaly detection.},
  archiveprefix = {arXiv},
  eprint = {2012.03808},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Lan_Dinh_2021_Perfect density models cannot guarantee anomaly detection.pdf},
  journal = {arXiv:2012.03808 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{lecunGradientbasedLearningApplied1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  year = {1998},
  month = nov,
  volume = {86},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  journal = {Proceedings of the IEEE},
  keywords = {Character recognition,Feature extraction,Hidden Markov models,Machine learning,Multi-layer neural network,Neural networks,Optical character recognition software,Optical computing,Pattern recognition,Principal component analysis},
  number = {11}
}

@article{lecunTutorialEnergyBasedLearning,
  title = {A {{Tutorial}} on {{Energy}}-{{Based Learning}}},
  author = {LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc'Aurelio and Huang, Fu Jie},
  pages = {59},
  abstract = {Energy-Based Models (EBMs) capture dependencies between variables by associating a scalar energy to each configuration of the variables. Inference consists in clamping the value of observed variables and finding configurations of the remaining variables that minimize the energy. Learning consists in finding an energy function in which observed configurations of the variables are given lower energies than unobserved ones. The EBM approach provides a common theoretical framework for many learning models, including traditional discriminative and generative approaches, as well as graph-transformer networks, conditional random fields, maximum margin Markov networks, and several manifold learning methods.},
  file = {/home/selflein/Zotero/storage/SZF6YDTI/LeCun et al. - A Tutorial on Energy-Based Learning.pdf},
  language = {en}
}

@article{leeSimpleUnifiedFramework2018a,
  title = {A {{Simple Unified Framework}} for {{Detecting Out}}-of-{{Distribution Samples}} and {{Adversarial Attacks}}},
  author = {Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  year = {2018},
  month = oct,
  abstract = {Detecting test samples drawn sufficiently far away from the training distribution statistically or adversarially is a fundamental requirement for deploying a good classifier in many real-world machine learning applications. However, deep neural networks with the softmax classifier are known to produce highly overconfident posterior distributions even for such abnormal samples. In this paper, we propose a simple yet effective method for detecting any abnormal samples, which is applicable to any pre-trained softmax neural classifier. We obtain the class conditional Gaussian distributions with respect to (low- and upper-level) features of the deep models under Gaussian discriminant analysis, which result in a confidence score based on the Mahalanobis distance. While most prior methods have been evaluated for detecting either out-of-distribution or adversarial samples, but not both, the proposed method achieves the state-of-the-art performances for both cases in our experiments. Moreover, we found that our proposed method is more robust in harsh cases, e.g., when the training dataset has noisy labels or small number of samples. Finally, we show that the proposed method enjoys broader usage by applying it to class-incremental learning: whenever out-of-distribution samples are detected, our classification rule can incorporate new classes well without further training deep models.},
  archiveprefix = {arXiv},
  eprint = {1807.03888},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Lee et al_2018_A Simple Unified Framework for Detecting Out-of-Distribution Samples and2.pdf},
  journal = {arXiv:1807.03888 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{leeTrainingConfidencecalibratedClassifiers2018,
  title = {Training {{Confidence}}-Calibrated {{Classifiers}} for {{Detecting Out}}-of-{{Distribution Samples}}},
  author = {Lee, Kimin and Lee, Honglak and Lee, Kibok and Shin, Jinwoo},
  year = {2018},
  month = feb,
  abstract = {The problem of detecting whether a test sample is from in-distribution (i.e., training distribution by a classifier) or out-of-distribution sufficiently different from it arises in many real-world machine learning applications. However, the state-of-art deep neural networks are known to be highly overconfident in their predictions, i.e., do not distinguish in- and out-of-distributions. Recently, to handle this issue, several threshold-based detectors have been proposed given pre-trained neural classifiers. However, the performance of prior works highly depends on how to train the classifiers since they only focus on improving inference procedures. In this paper, we develop a novel training method for classifiers so that such inference algorithms can work better. In particular, we suggest two additional terms added to the original loss (e.g., cross entropy). The first one forces samples from out-of-distribution less confident by the classifier and the second one is for (implicitly) generating most effective training samples for the first one. In essence, our method jointly trains both classification and generative neural networks for out-of-distribution. We demonstrate its effectiveness using deep convolutional neural networks on various popular image datasets.},
  archiveprefix = {arXiv},
  eprint = {1711.09325},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Lee et al_2018_Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution.pdf},
  journal = {arXiv:1711.09325 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{liangEnhancingReliabilityOutofdistribution2020,
  title = {Enhancing {{The Reliability}} of {{Out}}-of-Distribution {{Image Detection}} in {{Neural Networks}}},
  author = {Liang, Shiyu and Li, Yixuan and Srikant, R.},
  year = {2020},
  month = aug,
  abstract = {We consider the problem of detecting out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in- and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7\% to 4.3\% on the DenseNet (applied to CIFAR-10) when the true positive rate is 95\%.},
  archiveprefix = {arXiv},
  eprint = {1706.02690},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Liang et al_2020_Enhancing The Reliability of Out-of-distribution Image Detection in Neural.pdf},
  journal = {arXiv:1706.02690 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{liLearningEnergyBasedModels2019,
  title = {Learning {{Energy}}-{{Based Models}} in {{High}}-{{Dimensional Spaces}} with {{Multi}}-Scale {{Denoising Score Matching}}},
  author = {Li, Zengyi and Chen, Yubei and Sommer, Friedrich T.},
  year = {2019},
  month = dec,
  abstract = {Energy-Based Models (EBMs) assign unnormalized log-probability to data samples. This functionality has a variety of applications, such as sample synthesis, data denoising, sample restoration, outlier detection, Bayesian reasoning, and many more. But training of EBMs using standard maximum likelihood is extremely slow because it requires sampling from the model distribution. Score matching potentially alleviates this problem. In particular, denoising score matching \textbackslash citep\{vincent2011connection\} has been successfully used to train EBMs. Using noisy data samples with one fixed noise level, these models learn fast and yield good results in data denoising \textbackslash citep\{saremi2019neural\}. However, demonstrations of such models in high quality sample synthesis of high dimensional data were lacking. Recently, \textbackslash citet\{song2019generative\} have shown that a generative model trained by denoising score matching accomplishes excellent sample synthesis, when trained with data samples corrupted with multiple levels of noise. Here we provide analysis and empirical evidence showing that training with multiple noise levels is necessary when the data dimension is high. Leveraging this insight, we propose a novel EBM trained with multi-scale denoising score matching. Our model exhibits data generation performance comparable to state-of-the-art techniques such as GANs, and sets a new baseline for EBMs. The proposed model also provides density information and performs well in an image inpainting task.},
  archiveprefix = {arXiv},
  eprint = {1910.07762},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Li et al_2019_Learning Energy-Based Models in High-Dimensional Spaces with Multi-scale.pdf},
  journal = {arXiv:1910.07762 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@inproceedings{liu2015faceattributes,
  title = {Deep Learning Face Attributes in the Wild},
  booktitle = {Proceedings of International Conference on Computer Vision ({{ICCV}})},
  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  year = {2015},
  month = dec
}

@article{liuEnergybasedOutofdistributionDetection2020,
  title = {Energy-Based {{Out}}-of-Distribution {{Detection}}},
  author = {Liu, Weitang and Wang, Xiaoyun and Owens, John D. and Li, Yixuan},
  year = {2020},
  month = oct,
  abstract = {Determining whether inputs are out-of-distribution (OOD) is an essential building block for safely deploying machine learning models in the open world. However, previous methods relying on the softmax confidence score suffer from overconfident posterior distributions for OOD data. We propose a unified framework for OOD detection that uses an energy score. We show that energy scores better distinguish in- and out-of-distribution samples than the traditional approach using the softmax scores. Unlike softmax confidence scores, energy scores are theoretically aligned with the probability density of the inputs and are less susceptible to the overconfidence issue. Within this framework, energy can be flexibly used as a scoring function for any pre-trained neural classifier as well as a trainable cost function to shape the energy surface explicitly for OOD detection. On a CIFAR-10 pre-trained WideResNet, using the energy score reduces the average FPR (at TPR 95\%) by 18.03\% compared to the softmax confidence score. With energy-based training, our method outperforms the state-of-the-art on common benchmarks.},
  archiveprefix = {arXiv},
  eprint = {2010.03759},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Liu et al_2020_Energy-based Out-of-distribution Detection.pdf},
  journal = {arXiv:2010.03759 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{liuHybridDiscriminativeGenerativeTraining2020,
  title = {Hybrid {{Discriminative}}-{{Generative Training}} via {{Contrastive Learning}}},
  author = {Liu, Hao and Abbeel, Pieter},
  year = {2020},
  month = aug,
  abstract = {Contrastive learning and supervised learning have both seen significant progress and success. However, thus far they have largely been treated as two separate objectives, brought together only by having a shared neural network. In this paper we show that through the perspective of hybrid discriminative-generative training of energy-based models we can make a direct connection between contrastive learning and supervised learning. Beyond presenting this unified view, we show our specific choice of approximation of the energy-based loss outperforms the existing practice in terms of classification accuracy of WideResNet on CIFAR-10 and CIFAR-100. It also leads to improved performance on robustness, out-of-distribution detection, and calibration.},
  archiveprefix = {arXiv},
  eprint = {2007.09070},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Liu_Abbeel_2020_Hybrid Discriminative-Generative Training via Contrastive Learning.pdf},
  journal = {arXiv:2007.09070 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{liuSimplePrincipledUncertainty2020,
  title = {Simple and {{Principled Uncertainty Estimation}} with {{Deterministic Deep Learning}} via {{Distance Awareness}}},
  author = {Liu, Jeremiah Zhe and Lin, Zi and Padhy, Shreyas and Tran, Dustin and {Bedrax-Weiss}, Tania and Lakshminarayanan, Balaji},
  year = {2020},
  month = oct,
  abstract = {Bayesian neural networks (BNN) and deep ensembles are principled approaches to estimate the predictive uncertainty of a deep learning model. However their practicality in real-time, industrial-scale applications are limited due to their heavy memory and inference cost. This motivates us to study principled approaches to high-quality uncertainty estimation that require only a single deep neural network (DNN). By formalizing the uncertainty quantification as a minimax learning problem, we first identify input distance awareness, i.e., the model's ability to quantify the distance of a testing example from the training data in the input space, as a necessary condition for a DNN to achieve high-quality (i.e., minimax optimal) uncertainty estimation. We then propose Spectral-normalized Neural Gaussian Process (SNGP), a simple method that improves the distance-awareness ability of modern DNNs, by adding a weight normalization step during training and replacing the output layer with a Gaussian process. On a suite of vision and language understanding tasks and on modern architectures (Wide-ResNet and BERT), SNGP is competitive with deep ensembles in prediction, calibration and out-of-domain detection, and outperforms the other single-model approaches.},
  archiveprefix = {arXiv},
  eprint = {2006.10108},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Liu et al_2020_Simple and Principled Uncertainty Estimation with Deterministic Deep Learning.pdf},
  journal = {arXiv:2006.10108 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{louNeuralManifoldOrdinary2020,
  title = {Neural {{Manifold Ordinary Differential Equations}}},
  author = {Lou, Aaron and Lim, Derek and Katsman, Isay and Huang, Leo and Jiang, Qingxuan and Lim, Ser-Nam and De Sa, Christopher},
  year = {2020},
  month = jun,
  abstract = {To better conform to data geometry, recent deep generative modelling techniques adapt Euclidean constructions to non-Euclidean spaces. In this paper, we study normalizing flows on manifolds. Previous work has developed flow models for specific cases; however, these advancements hand craft layers on a manifold-by-manifold basis, restricting generality and inducing cumbersome design constraints. We overcome these issues by introducing Neural Manifold Ordinary Differential Equations, a manifold generalization of Neural ODEs, which enables the construction of Manifold Continuous Normalizing Flows (MCNFs). MCNFs require only local geometry (therefore generalizing to arbitrary manifolds) and compute probabilities with continuous change of variables (allowing for a simple and expressive flow construction). We find that leveraging continuous manifold dynamics produces a marked improvement for both density estimation and downstream tasks.},
  archiveprefix = {arXiv},
  eprint = {2006.10254},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Lou et al_2020_Neural Manifold Ordinary Differential Equations.pdf},
  journal = {arXiv:2006.10254 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Differential Geometry,Statistics - Machine Learning},
  primaryclass = {cs, math, stat}
}

@article{mackowiakTrainingNormalizingFlows2021,
  title = {Training {{Normalizing Flows}} with the {{Information Bottleneck}} for {{Competitive Generative Classification}}},
  author = {Mackowiak, Radek and Rother, Carsten and K{\"o}the, Ullrich},
  year = {2021},
  month = jan,
  abstract = {The Information Bottleneck (IB) objective uses information theory to formulate a task-performance versus robustness trade-off. It has been successfully applied in the standard discriminative classification setting. We pose the question whether the IB can also be used to train generative likelihood models such as normalizing flows. Since normalizing flows use invertible network architectures (INNs), they are information-preserving by construction. This seems contradictory to the idea of a bottleneck. In this work, firstly, we develop the theory and methodology of IB-INNs, a class of conditional normalizing flows where INNs are trained using the IB objective: Introducing a small amount of \{\textbackslash em controlled\} information loss allows for an asymptotically exact formulation of the IB, while keeping the INN's generative capabilities intact. Secondly, we investigate the properties of these models experimentally, specifically used as generative classifiers. This model class offers advantages such as improved uncertainty quantification and out-of-distribution detection, but traditional generative classifier solutions suffer considerably in classification accuracy. We find the trade-off parameter in the IB controls a mix of generative capabilities and accuracy close to standard classifiers. Empirically, our uncertainty estimates in this mixed regime compare favourably to conventional generative and discriminative classifiers.},
  archiveprefix = {arXiv},
  eprint = {2001.06448},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ardizzone et al_2021_Training Normalizing Flows with the Information Bottleneck for Competitive.pdf},
  journal = {arXiv:2001.06448 [cs, stat]},
  keywords = {68T01,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{malininEnsembleDistributionDistillation2019,
  title = {Ensemble {{Distribution Distillation}}},
  author = {Malinin, Andrey and Mlodozeniec, Bruno and Gales, Mark},
  year = {2019},
  month = nov,
  abstract = {Ensembles of models often yield improvements in system performance. These ensemble approaches have also been empirically shown to yield robust measures of uncertainty, and are capable of distinguishing between different \textbackslash emph\{forms\} of uncertainty. However, ensembles come at a computational and memory cost which may be prohibitive for many applications. There has been significant work done on the distillation of an ensemble into a single model. Such approaches decrease computational cost and allow a single model to achieve an accuracy comparable to that of an ensemble. However, information about the \textbackslash emph\{diversity\} of the ensemble, which can yield estimates of different forms of uncertainty, is lost. This work considers the novel task of \textbackslash emph\{Ensemble Distribution Distillation\} (EnD\$\^2\$) --- distilling the distribution of the predictions from an ensemble, rather than just the average prediction, into a single model. EnD\$\^2\$ enables a single model to retain both the improved classification performance of ensemble distillation as well as information about the diversity of the ensemble, which is useful for uncertainty estimation. A solution for EnD\$\^2\$ based on Prior Networks, a class of models which allow a single neural network to explicitly model a distribution over output distributions, is proposed in this work. The properties of EnD\$\^2\$ are investigated on both an artificial dataset, and on the CIFAR-10, CIFAR-100 and TinyImageNet datasets, where it is shown that EnD\$\^2\$ can approach the classification performance of an ensemble, and outperforms both standard DNNs and Ensemble Distillation on the tasks of misclassification and out-of-distribution input detection.},
  archiveprefix = {arXiv},
  eprint = {1905.00076},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Malinin et al_2019_Ensemble Distribution Distillation.pdf},
  journal = {arXiv:1905.00076 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{malininPredictiveUncertaintyEstimation2018,
  title = {Predictive {{Uncertainty Estimation}} via {{Prior Networks}}},
  author = {Malinin, Andrey and Gales, Mark},
  year = {2018},
  month = nov,
  abstract = {Estimating how uncertain an AI system is in its predictions is important to improve the safety of such systems. Uncertainty in predictive can result from uncertainty in model parameters, irreducible data uncertainty and uncertainty due to distributional mismatch between the test and training data distributions. Different actions might be taken depending on the source of the uncertainty so it is important to be able to distinguish between them. Recently, baseline tasks and metrics have been defined and several practical methods to estimate uncertainty developed. These methods, however, attempt to model uncertainty due to distributional mismatch either implicitly through model uncertainty or as data uncertainty. This work proposes a new framework for modeling predictive uncertainty called Prior Networks (PNs) which explicitly models distributional uncertainty. PNs do this by parameterizing a prior distribution over predictive distributions. This work focuses on uncertainty for classification and evaluates PNs on the tasks of identifying out-of-distribution (OOD) samples and detecting misclassification on the MNIST dataset, where they are found to outperform previous methods. Experiments on synthetic and MNIST and CIFAR-10 data show that unlike previous non-Bayesian methods PNs are able to distinguish between data and distributional uncertainty.},
  archiveprefix = {arXiv},
  eprint = {1802.10501},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Malinin_Gales_2018_Predictive Uncertainty Estimation via Prior Networks.pdf},
  journal = {arXiv:1802.10501 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{malininReverseKLDivergenceTraining2019,
  title = {Reverse {{KL}}-{{Divergence Training}} of {{Prior Networks}}: {{Improved Uncertainty}} and {{Adversarial Robustness}}},
  shorttitle = {Reverse {{KL}}-{{Divergence Training}} of {{Prior Networks}}},
  author = {Malinin, Andrey and Gales, Mark},
  year = {2019},
  month = dec,
  abstract = {Ensemble approaches for uncertainty estimation have recently been applied to the tasks of misclassification detection, out-of-distribution input detection and adversarial attack detection. Prior Networks have been proposed as an approach to efficiently \textbackslash emph\{emulate\} an ensemble of models for classification by parameterising a Dirichlet prior distribution over output distributions. These models have been shown to outperform alternative ensemble approaches, such as Monte-Carlo Dropout, on the task of out-of-distribution input detection. However, scaling Prior Networks to complex datasets with many classes is difficult using the training criteria originally proposed. This paper makes two contributions. First, we show that the appropriate training criterion for Prior Networks is the \textbackslash emph\{reverse\} KL-divergence between Dirichlet distributions. This addresses issues in the nature of the training data target distributions, enabling prior networks to be successfully trained on classification tasks with arbitrarily many classes, as well as improving out-of-distribution detection performance. Second, taking advantage of this new training criterion, this paper investigates using Prior Networks to detect adversarial attacks and proposes a generalized form of adversarial training. It is shown that the construction of successful \textbackslash emph\{adaptive\} whitebox attacks, which affect the prediction and evade detection, against Prior Networks trained on CIFAR-10 and CIFAR-100 using the proposed approach requires a greater amount of computational effort than against networks defended using standard adversarial training or MC-dropout.},
  archiveprefix = {arXiv},
  eprint = {1905.13472},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Malinin_Gales_2019_Reverse KL-Divergence Training of Prior Networks.pdf},
  journal = {arXiv:1905.13472 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{malininReverseKLDivergenceTraining2019a,
  title = {Reverse {{KL}}-{{Divergence Training}} of {{Prior Networks}}: {{Improved Uncertainty}} and {{Adversarial Robustness}}},
  shorttitle = {Reverse {{KL}}-{{Divergence Training}} of {{Prior Networks}}},
  author = {Malinin, Andrey and Gales, Mark},
  year = {2019},
  month = dec,
  abstract = {Ensemble approaches for uncertainty estimation have recently been applied to the tasks of misclassification detection, out-of-distribution input detection and adversarial attack detection. Prior Networks have been proposed as an approach to efficiently \textbackslash emph\{emulate\} an ensemble of models for classification by parameterising a Dirichlet prior distribution over output distributions. These models have been shown to outperform alternative ensemble approaches, such as Monte-Carlo Dropout, on the task of out-of-distribution input detection. However, scaling Prior Networks to complex datasets with many classes is difficult using the training criteria originally proposed. This paper makes two contributions. First, we show that the appropriate training criterion for Prior Networks is the \textbackslash emph\{reverse\} KL-divergence between Dirichlet distributions. This addresses issues in the nature of the training data target distributions, enabling prior networks to be successfully trained on classification tasks with arbitrarily many classes, as well as improving out-of-distribution detection performance. Second, taking advantage of this new training criterion, this paper investigates using Prior Networks to detect adversarial attacks and proposes a generalized form of adversarial training. It is shown that the construction of successful \textbackslash emph\{adaptive\} whitebox attacks, which affect the prediction and evade detection, against Prior Networks trained on CIFAR-10 and CIFAR-100 using the proposed approach requires a greater amount of computational effort than against networks defended using standard adversarial training or MC-dropout.},
  archiveprefix = {arXiv},
  eprint = {1905.13472},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Malinin_Gales_2019_Reverse KL-Divergence Training of Prior Networks2.pdf},
  journal = {arXiv:1905.13472 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{malininUncertaintyEstimationAutoregressive2021,
  title = {Uncertainty {{Estimation}} in {{Autoregressive Structured Prediction}}},
  author = {Malinin, Andrey and Gales, Mark},
  year = {2021},
  month = feb,
  abstract = {Uncertainty estimation is important for ensuring safety and robustness of AI systems. While most research in the area has focused on un-structured prediction tasks, limited work has investigated general uncertainty estimation approaches for structured prediction. Thus, this work aims to investigate uncertainty estimation for autoregressive structured prediction tasks within a single unified and interpretable probabilistic ensemble-based framework. We consider: uncertainty estimation for sequence data at the token-level and complete sequence-level; interpretations for, and applications of, various measures of uncertainty; and discuss both the theoretical and practical challenges associated with obtaining them. This work also provides baselines for token-level and sequence-level error detection, and sequence-level out-of-domain input detection on the WMT'14 English-French and WMT'17 English-German translation and LibriSpeech speech recognition datasets.},
  archiveprefix = {arXiv},
  eprint = {2002.07650},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Malinin_Gales_2021_Uncertainty Estimation in Autoregressive Structured Prediction.pdf},
  journal = {arXiv:2002.07650 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{mathiasenWhatIfNeural2020,
  title = {What If {{Neural Networks}} Had {{SVDs}}?},
  author = {Mathiasen, Alexander and Hvilsh{\o}j, Frederik and J{\o}rgensen, Jakob R{\o}dsgaard and Nasery, Anshul and Mottin, Davide},
  year = {2020},
  month = sep,
  abstract = {Various Neural Networks employ time-consuming matrix operations like matrix inversion. Many such matrix operations are faster to compute given the Singular Value Decomposition (SVD). Previous work allows using the SVD in Neural Networks without computing it. In theory, the techniques can speed up matrix operations, however, in practice, they are not fast enough. We present an algorithm that is fast enough to speed up several matrix operations. The algorithm increases the degree of parallelism of an underlying matrix multiplication \$H\textbackslash cdot X\$ where \$H\$ is an orthogonal matrix represented by a product of Householder matrices. Code is available at www.github.com/AlexanderMath/fasth .},
  archiveprefix = {arXiv},
  eprint = {2009.13977},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Mathiasen et al_2020_What if Neural Networks had SVDs.pdf},
  journal = {arXiv:2009.13977 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{meinkeNeuralNetworksThat2020,
  title = {Towards Neural Networks That Provably Know When They Don't Know},
  author = {Meinke, Alexander and Hein, Matthias},
  year = {2020},
  month = feb,
  abstract = {It has recently been shown that ReLU networks produce arbitrarily over-confident predictions far away from the training data. Thus, ReLU networks do not know when they don't know. However, this is a highly important property in safety critical applications. In the context of out-of-distribution detection (OOD) there have been a number of proposals to mitigate this problem but none of them are able to make any mathematical guarantees. In this paper we propose a new approach to OOD which overcomes both problems. Our approach can be used with ReLU networks and provides provably low confidence predictions far away from the training data as well as the first certificates for low confidence predictions in a neighborhood of an out-distribution point. In the experiments we show that state-of-the-art methods fail in this worst-case setting whereas our model can guarantee its performance while retaining state-of-the-art OOD performance.},
  archiveprefix = {arXiv},
  eprint = {1909.12180},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Meinke_Hein_2020_Towards neural networks that provably know when they don't know.pdf},
  journal = {arXiv:1909.12180 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{miyatoSpectralNormalizationGenerative2018,
  title = {Spectral {{Normalization}} for {{Generative Adversarial Networks}}},
  author = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  year = {2018},
  month = feb,
  abstract = {One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.},
  archiveprefix = {arXiv},
  eprint = {1802.05957},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Miyato et al_2018_Spectral Normalization for Generative Adversarial Networks.pdf},
  journal = {arXiv:1802.05957 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{morningstarDensityStatesEstimation2020,
  title = {Density of {{States Estimation}} for {{Out}}-of-{{Distribution Detection}}},
  author = {Morningstar, Warren R. and Ham, Cusuh and Gallagher, Andrew G. and Lakshminarayanan, Balaji and Alemi, Alexander A. and Dillon, Joshua V.},
  year = {2020},
  month = jun,
  abstract = {Perhaps surprisingly, recent studies have shown probabilistic model likelihoods have poor specificity for out-of-distribution (OOD) detection and often assign higher likelihoods to OOD data than in-distribution data. To ameliorate this issue we propose DoSE, the density of states estimator. Drawing on the statistical physics notion of ``density of states,'' the DoSE decision rule avoids direct comparison of model probabilities, and instead utilizes the ``probability of the model probability,'' or indeed the frequency of any reasonable statistic. The frequency is calculated using nonparametric density estimators (e.g., KDE and one-class SVM) which measure the typicality of various model statistics given the training data and from which we can flag test points with low typicality as anomalous. Unlike many other methods, DoSE requires neither labeled data nor OOD examples. DoSE is modular and can be trivially applied to any existing, trained model. We demonstrate DoSE's state-of-the-art performance against other unsupervised OOD detectors on previously established ``hard'' benchmarks.},
  archiveprefix = {arXiv},
  eprint = {2006.09273},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Morningstar et al_2020_Density of States Estimation for Out-of-Distribution Detection.pdf},
  journal = {arXiv:2006.09273 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{murphyNewVectorPartition1973,
  title = {A {{New Vector Partition}} of the {{Probability Score}}},
  author = {Murphy, Allan H.},
  year = {1973},
  month = jun,
  volume = {12},
  pages = {595--600},
  publisher = {{American Meteorological Society}},
  issn = {1520-0450},
  doi = {10.1175/1520-0450(1973)012<0595:ANVPOT>2.0.CO;2},
  abstract = {{$<$}section class="abstract"{$><$}h2 class="abstractTitle text-title my-1" id="d161e2"{$>$}Abstract{$<$}/h2{$><$}p{$>$}A {$<$}em{$>$}new{$<$}/em{$>$} vector partition of the probability, or Brier, score ({$<$}em{$>$}PS{$<$}/em{$>$}) is formulated and the nature and properties of this partition are described. The relationships between the terms in this partition and the terms in the {$<$}em{$>$}original{$<$}/em{$>$} vector partition of the {$<$}em{$>$}PS{$<$}/em{$>$} are indicated. The new partition consists of three terms: 1) a measure of the uncertainty inherent in the events, or states, on the occasions of concern (namely, the {$<$}em{$>$}PS{$<$}/em{$>$} for the sample relative frequencies); 2) a measure of the reliability of the forecasts; and 3) a new measure of the resolution of the forecasts. These measures of reliability and resolution are and are not, respectively, equivalent (i.e., linearly related) to the measures of reliability and resolution provided by the original partition. Two sample collections of probability forecasts are used to illustrate the differences and relationships between these partitions. Finally, the two partitions are compared, with particular reference to the attributes of the forecasts with which the partitions are concerned, the interpretation of the partitions in geometric terms, and the use of the partitions as the bases for the formulation of measures to evaluate probability forecasts. The results of these comparisons indicate that the new partition offers certain advantages vis-\`a-vis the original partition.{$<$}/p{$><$}/section{$>$}},
  chapter = {Journal of Applied Meteorology and Climatology},
  file = {/home/selflein/Documents/Zotero/papers/Murphy_1973_A New Vector Partition of the Probability Score.pdf},
  journal = {Journal of Applied Meteorology and Climatology},
  language = {EN},
  number = {4}
}

@article{nalisnickDeepGenerativeModels2019,
  title = {Do {{Deep Generative Models Know What They Don}}'t {{Know}}?},
  author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
  year = {2019},
  month = feb,
  abstract = {A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are widely viewed to be robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs. In this paper we challenge this assumption. We find that the density learned by flow-based models, VAEs, and PixelCNNs cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. Moreover, we find evidence of this phenomenon when pairing several popular image data sets: FashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN. To investigate this curious behavior, we focus analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find such behavior persists even when we restrict the flows to constant-volume transformations. These transformations admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature. Our results caution against using the density estimates from deep generative models to identify inputs similar to the training distribution until their behavior for out-of-distribution inputs is better understood.},
  archiveprefix = {arXiv},
  eprint = {1810.09136},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Nalisnick et al_2019_Do Deep Generative Models Know What They Don't Know.pdf},
  journal = {arXiv:1810.09136 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{nalisnickDetectingOutofDistributionInputs2019,
  title = {Detecting {{Out}}-of-{{Distribution Inputs}} to {{Deep Generative Models Using Typicality}}},
  author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Lakshminarayanan, Balaji},
  year = {2019},
  month = oct,
  abstract = {Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data (Nalisnick et al., 2019; Choi et al., 2019). We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density. In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed. To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods. The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated. We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. (2019).},
  archiveprefix = {arXiv},
  eprint = {1906.02994},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Nalisnick et al_2019_Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality.pdf},
  journal = {arXiv:1906.02994 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{nalisnickDetectingOutofDistributionInputs2019a,
  title = {Detecting {{Out}}-of-{{Distribution Inputs}} to {{Deep Generative Models Using Typicality}}},
  author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Lakshminarayanan, Balaji},
  year = {2019},
  month = oct,
  abstract = {Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data (Nalisnick et al., 2019; Choi et al., 2019). We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density. In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed. To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods. The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated. We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. (2019).},
  archiveprefix = {arXiv},
  eprint = {1906.02994},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Nalisnick et al_2019_Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality2.pdf},
  journal = {arXiv:1906.02994 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{netzerReadingDigitsNatural2011,
  title = {Reading {{Digits}} in {{Natural Images}} with {{Unsupervised Feature Learning}}},
  author = {Netzer, Yuval and Wang, T. and Coates, A. and Bissacco, A. and Wu, B. and Ng, A.},
  year = {2011},
  abstract = {Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks.},
  journal = {undefined},
  language = {en}
}

@article{nijkampAnatomyMCMCBasedMaximum2019,
  title = {On the {{Anatomy}} of {{MCMC}}-{{Based Maximum Likelihood Learning}} of {{Energy}}-{{Based Models}}},
  author = {Nijkamp, Erik and Hill, Mitch and Han, Tian and Zhu, Song-Chun and Wu, Ying Nian},
  year = {2019},
  month = nov,
  abstract = {This study investigates the effects of Markov chain Monte Carlo (MCMC) sampling in unsupervised Maximum Likelihood (ML) learning. Our attention is restricted to the family of unnormalized probability densities for which the negative log density (or energy function) is a ConvNet. We find that many of the techniques used to stabilize training in previous studies are not necessary. ML learning with a ConvNet potential requires only a few hyper-parameters and no regularization. Using this minimal framework, we identify a variety of ML learning outcomes that depend solely on the implementation of MCMC sampling. On one hand, we show that it is easy to train an energy-based model which can sample realistic images with short-run Langevin. ML can be effective and stable even when MCMC samples have much higher energy than true steady-state samples throughout training. Based on this insight, we introduce an ML method with purely noise-initialized MCMC, high-quality short-run synthesis, and the same budget as ML with informative MCMC initialization such as CD or PCD. Unlike previous models, our energy model can obtain realistic high-diversity samples from a noise signal after training. On the other hand, ConvNet potentials learned with non-convergent MCMC do not have a valid steady-state and cannot be considered approximate unnormalized densities of the training data because long-run MCMC samples differ greatly from observed images. We show that it is much harder to train a ConvNet potential to learn a steady-state over realistic images. To our knowledge, long-run MCMC samples of all previous models lose the realism of short-run samples. With correct tuning of Langevin noise, we train the first ConvNet potentials for which long-run and steady-state MCMC samples are realistic images.},
  archiveprefix = {arXiv},
  eprint = {1903.12370},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Nijkamp et al_2019_On the Anatomy of MCMC-Based Maximum Likelihood Learning of Energy-Based Models.pdf},
  journal = {arXiv:1903.12370 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{nijkampLearningNonConvergentNonPersistent2019,
  title = {Learning {{Non}}-{{Convergent Non}}-{{Persistent Short}}-{{Run MCMC Toward Energy}}-{{Based Model}}},
  author = {Nijkamp, Erik and Hill, Mitch and Zhu, Song-Chun and Wu, Ying Nian},
  year = {2019},
  month = nov,
  abstract = {This paper studies a curious phenomenon in learning energy-based model (EBM) using MCMC. In each learning iteration, we generate synthesized examples by running a non-convergent, non-mixing, and non-persistent short-run MCMC toward the current model, always starting from the same initial distribution such as uniform noise distribution, and always running a fixed number of MCMC steps. After generating synthesized examples, we then update the model parameters according to the maximum likelihood learning gradient, as if the synthesized examples are fair samples from the current model. We treat this non-convergent short-run MCMC as a learned generator model or a flow model. We provide arguments for treating the learned non-convergent short-run MCMC as a valid model. We show that the learned short-run MCMC is capable of generating realistic images. More interestingly, unlike traditional EBM or MCMC, the learned short-run MCMC is capable of reconstructing observed images and interpolating between images, like generator or flow models. The code can be found in the Appendix.},
  archiveprefix = {arXiv},
  eprint = {1904.09770},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Nijkamp et al_2019_Learning Non-Convergent Non-Persistent Short-Run MCMC Toward Energy-Based Model.pdf},
  journal = {arXiv:1904.09770 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{ovadiaCanYouTrust2019,
  title = {Can {{You Trust Your Model}}'s {{Uncertainty}}? {{Evaluating Predictive Uncertainty Under Dataset Shift}}},
  shorttitle = {Can {{You Trust Your Model}}'s {{Uncertainty}}?},
  author = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D. and Nowozin, Sebastian and Dillon, Joshua V. and Lakshminarayanan, Balaji and Snoek, Jasper},
  year = {2019},
  month = dec,
  abstract = {Modern machine learning methods including deep learning have achieved great success in predictive accuracy for supervised learning tasks, but may still fall short in giving useful estimates of their predictive \{\textbackslash em uncertainty\}. Quantifying uncertainty is especially critical in real-world settings, which often involve input distributions that are shifted from the training distribution due to a variety of factors including sample bias and non-stationarity. In such settings, well calibrated uncertainty estimates convey information about when a model's output should (or should not) be trusted. Many probabilistic deep learning methods, including Bayesian-and non-Bayesian methods, have been proposed in the literature for quantifying predictive uncertainty, but to our knowledge there has not previously been a rigorous large-scale empirical comparison of these methods under dataset shift. We present a large-scale benchmark of existing state-of-the-art methods on classification problems and investigate the effect of dataset shift on accuracy and calibration. We find that traditional post-hoc calibration does indeed fall short, as do several other previous methods. However, some methods that marginalize over models give surprisingly strong results across a broad spectrum of tasks.},
  archiveprefix = {arXiv},
  eprint = {1906.02530},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ovadia et al_2019_Can You Trust Your Model's Uncertainty.pdf},
  journal = {arXiv:1906.02530 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{papamakariosNormalizingFlowsProbabilistic2021,
  title = {Normalizing {{Flows}} for {{Probabilistic Modeling}} and {{Inference}}},
  author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  year = {2021},
  volume = {22},
  pages = {1--64},
  issn = {1533-7928},
  file = {/home/selflein/Documents/Zotero/papers/Papamakarios et al_2021_Normalizing Flows for Probabilistic Modeling and Inference.pdf},
  journal = {Journal of Machine Learning Research},
  number = {57}
}

@article{ramalhoDensityEstimationRepresentation2019,
  title = {Density Estimation in Representation Space to Predict Model Uncertainty},
  author = {Ramalho, Tiago and Miranda, Miguel},
  year = {2019},
  month = oct,
  abstract = {Deep learning models frequently make incorrect predictions with high confidence when presented with test examples that are not well represented in their training dataset. We propose a novel and straightforward approach to estimate prediction uncertainty in a pre-trained neural network model. Our method estimates the training data density in representation space for a novel input. A neural network model then uses this information to determine whether we expect the pre-trained model to make a correct prediction. This uncertainty model is trained by predicting in-distribution errors, but can detect out-of-distribution data without having seen any such example. We test our method for a state-of-the art image classification model in the settings of both in-distribution uncertainty estimation as well as out-of-distribution detection.},
  archiveprefix = {arXiv},
  eprint = {1908.07235},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ramalho_Miranda_2019_Density estimation in representation space to predict model uncertainty.pdf},
  journal = {arXiv:1908.07235 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{renLikelihoodRatiosOutofDistribution2019,
  title = {Likelihood {{Ratios}} for {{Out}}-of-{{Distribution Detection}}},
  author = {Ren, Jie and Liu, Peter J. and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and DePristo, Mark A. and Dillon, Joshua V. and Lakshminarayanan, Balaji},
  year = {2019},
  month = dec,
  abstract = {Discriminative neural networks offer little or no performance guarantees when deployed on data not generated by the same process as the training distribution. On such out-of-distribution (OOD) inputs, the prediction may not only be erroneous, but confidently so, limiting the safe deployment of classifiers in real-world applications. One such challenging application is bacteria identification based on genomic sequences, which holds the promise of early detection of diseases, but requires a model that can output low confidence predictions on OOD genomic sequences from new bacteria that were not present in the training data. We introduce a genomics dataset for OOD detection that allows other researchers to benchmark progress on this important problem. We investigate deep generative model based approaches for OOD detection and observe that the likelihood score is heavily affected by population level background statistics. We propose a likelihood ratio method for deep generative models which effectively corrects for these confounding background statistics. We benchmark the OOD detection performance of the proposed method against existing approaches on the genomics dataset and show that our method achieves state-of-the-art performance. We demonstrate the generality of the proposed method by showing that it significantly improves OOD detection when applied to deep generative models of images.},
  archiveprefix = {arXiv},
  eprint = {1906.02845},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ren et al_2019_Likelihood Ratios for Out-of-Distribution Detection.pdf},
  journal = {arXiv:1906.02845 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{rezendeVariationalInferenceNormalizing2016,
  title = {Variational {{Inference}} with {{Normalizing Flows}}},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
  year = {2016},
  month = jun,
  abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
  archiveprefix = {arXiv},
  eprint = {1505.05770},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Rezende_Mohamed_2016_Variational Inference with Normalizing Flows.pdf},
  journal = {arXiv:1505.05770 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  primaryclass = {cs, stat}
}

@article{ruffUnifyingReviewDeep2021,
  title = {A {{Unifying Review}} of {{Deep}} and {{Shallow Anomaly Detection}}},
  author = {Ruff, Lukas and Kauffmann, Jacob R. and Vandermeulen, Robert A. and Montavon, Gr{\'e}goire and Samek, Wojciech and Kloft, Marius and Dietterich, Thomas G. and M{\"u}ller, Klaus-Robert},
  year = {2021},
  pages = {1--40},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2021.3052449},
  abstract = {Deep learning approaches to anomaly detection have recently improved the state of the art in detection performance on complex datasets such as large collections of images or text. These results have sparked a renewed interest in the anomaly detection problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review we aim to identify the common underlying principles as well as the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic 'shallow' and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that is enriched by the use of recent explainability techniques, and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in anomaly detection.},
  archiveprefix = {arXiv},
  eprint = {2009.11732},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ruff et al_2021_A Unifying Review of Deep and Shallow Anomaly Detection.pdf},
  journal = {Proceedings of the IEEE},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{saitoPrecisionRecallPlotMore2015,
  title = {The {{Precision}}-{{Recall Plot Is More Informative}} than the {{ROC Plot When Evaluating Binary Classifiers}} on {{Imbalanced Datasets}}},
  author = {Saito, Takaya and Rehmsmeier, Marc},
  year = {2015},
  month = mar,
  volume = {10},
  pages = {e0118432},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0118432},
  abstract = {Binary classifiers are routinely evaluated with performance measures such as sensitivity and specificity, and performance is frequently illustrated with Receiver Operating Characteristics (ROC) plots. Alternative measures such as positive predictive value (PPV) and the associated Precision/Recall (PRC) plots are used less frequently. Many bioinformatics studies develop and evaluate classifiers that are to be applied to strongly imbalanced datasets in which the number of negatives outweighs the number of positives significantly. While ROC plots are visually appealing and provide an overview of a classifier's performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios. We show here that the visual interpretability of ROC plots in the context of imbalanced datasets can be deceptive with respect to conclusions about the reliability of classification performance, owing to an intuitive but wrong interpretation of specificity. PRC plots, on the other hand, can provide the viewer with an accurate prediction of future classification performance due to the fact that they evaluate the fraction of true positives among positive predictions. Our findings have potential implications for the interpretation of a large number of studies that use ROC plots on imbalanced datasets.},
  file = {/home/selflein/Documents/Zotero/papers/Saito_Rehmsmeier_2015_The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating.pdf},
  journal = {PLOS ONE},
  keywords = {Bioinformatics,Caenorhabditis elegans,Exponential functions,Genome-wide association studies,Interpolation,Measurement,MicroRNAs,Support vector machines},
  language = {en},
  number = {3}
}

@article{saremiDeepEnergyEstimator2018,
  title = {Deep {{Energy Estimator Networks}}},
  author = {Saremi, Saeed and Mehrjou, Arash and Sch{\"o}lkopf, Bernhard and Hyv{\"a}rinen, Aapo},
  year = {2018},
  month = may,
  abstract = {Density estimation is a fundamental problem in statistical learning. This problem is especially challenging for complex high-dimensional data due to the curse of dimensionality. A promising solution to this problem is given here in an inference-free hierarchical framework that is built on score matching. We revisit the Bayesian interpretation of the score function and the Parzen score matching, and construct a multilayer perceptron with a scalable objective for learning the energy (i.e. the unnormalized log-density), which is then optimized with stochastic gradient descent. In addition, the resulting deep energy estimator network (DEEN) is designed as products of experts. We present the utility of DEEN in learning the energy, the score function, and in single-step denoising experiments for synthetic and high-dimensional data. We also diagnose stability problems in the direct estimation of the score function that had been observed for denoising autoencoders.},
  archiveprefix = {arXiv},
  eprint = {1805.08306},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Saremi et al_2018_Deep Energy Estimator Networks.pdf},
  journal = {arXiv:1805.08306 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{saremiDeepEnergyEstimator2018a,
  title = {Deep {{Energy Estimator Networks}}},
  author = {Saremi, Saeed and Mehrjou, Arash and Sch{\"o}lkopf, Bernhard and Hyv{\"a}rinen, Aapo},
  year = {2018},
  month = may,
  abstract = {Density estimation is a fundamental problem in statistical learning. This problem is especially challenging for complex high-dimensional data due to the curse of dimensionality. A promising solution to this problem is given here in an inference-free hierarchical framework that is built on score matching. We revisit the Bayesian interpretation of the score function and the Parzen score matching, and construct a multilayer perceptron with a scalable objective for learning the energy (i.e. the unnormalized log-density), which is then optimized with stochastic gradient descent. In addition, the resulting deep energy estimator network (DEEN) is designed as products of experts. We present the utility of DEEN in learning the energy, the score function, and in single-step denoising experiments for synthetic and high-dimensional data. We also diagnose stability problems in the direct estimation of the score function that had been observed for denoising autoencoders.},
  archiveprefix = {arXiv},
  eprint = {1805.08306},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Saremi et al_2018_Deep Energy Estimator Networks2.pdf},
  journal = {arXiv:1805.08306 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{saremiNeuralEmpiricalBayes2020,
  title = {Neural {{Empirical Bayes}}},
  author = {Saremi, Saeed and Hyvarinen, Aapo},
  year = {2020},
  month = apr,
  abstract = {We unify \$\textbackslash textit\{kernel density estimation\}\$ and \$\textbackslash textit\{empirical Bayes\}\$ and address a set of problems in unsupervised learning with a geometric interpretation of those methods, rooted in the \$\textbackslash textit\{concentration of measure\}\$ phenomenon. Kernel density is viewed symbolically as \$X\textbackslash rightharpoonup Y\$ where the random variable \$X\$ is smoothed to \$Y= X+N(0,\textbackslash sigma\^2 I\_d)\$, and empirical Bayes is the machinery to denoise in a least-squares sense, which we express as \$X \textbackslash leftharpoondown Y\$. A learning objective is derived by combining these two, symbolically captured by \$X \textbackslash rightleftharpoons Y\$. Crucially, instead of using the original nonparametric estimators, we parametrize \$\textbackslash textit\{the energy function\}\$ with a neural network denoted by \$\textbackslash phi\$; at optimality, \$\textbackslash nabla \textbackslash phi \textbackslash approx -\textbackslash nabla \textbackslash log f\$ where \$f\$ is the density of \$Y\$. The optimization problem is abstracted as interactions of high-dimensional spheres which emerge due to the concentration of isotropic gaussians. We introduce two algorithmic frameworks based on this machinery: (i) a "walk-jump" sampling scheme that combines Langevin MCMC (walks) and empirical Bayes (jumps), and (ii) a probabilistic framework for \$\textbackslash textit\{associative memory\}\$, called NEBULA, defined \textbackslash `\{a\} la Hopfield by the \$\textbackslash textit\{gradient flow\}\$ of the learned energy to a set of attractors. We finish the paper by reporting the emergence of very rich "creative memories" as attractors of NEBULA for highly-overlapping spheres.},
  archiveprefix = {arXiv},
  eprint = {1903.02334},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Saremi_Hyvarinen_2020_Neural Empirical Bayes.pdf},
  journal = {arXiv:1903.02334 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{schirrmeisterUnderstandingAnomalyDetection2020,
  title = {Understanding {{Anomaly Detection}} with {{Deep Invertible Networks}} through {{Hierarchies}} of {{Distributions}} and {{Features}}},
  author = {Schirrmeister, Robin Tibor and Zhou, Yuxuan and Ball, Tonio and Zhang, Dan},
  year = {2020},
  month = nov,
  abstract = {Deep generative networks trained via maximum likelihood on a natural image dataset like CIFAR10 often assign high likelihoods to images from datasets with different objects (e.g., SVHN). We refine previous investigations of this failure at anomaly detection for invertible generative networks and provide a clear explanation of it as a combination of model bias and domain prior: Convolutional networks learn similar low-level feature distributions when trained on any natural image dataset and these low-level features dominate the likelihood. Hence, when the discriminative features between inliers and outliers are on a high-level, e.g., object shapes, anomaly detection becomes particularly challenging. To remove the negative impact of model bias and domain prior on detecting high-level differences, we propose two methods, first, using the log likelihood ratios of two identical models, one trained on the in-distribution data (e.g., CIFAR10) and the other one on a more general distribution of images (e.g., 80 Million Tiny Images). We also derive a novel outlier loss for the in-distribution network on samples from the more general distribution to further improve the performance. Secondly, using a multi-scale model like Glow, we show that low-level features are mainly captured at early scales. Therefore, using only the likelihood contribution of the final scale performs remarkably well for detecting high-level feature differences of the out-of-distribution and the in-distribution. This method is especially useful if one does not have access to a suitable general distribution. Overall, our methods achieve strong anomaly detection performance in the unsupervised setting, and only slightly underperform state-of-the-art classifier-based methods in the supervised setting. Code can be found at https://github.com/boschresearch/hierarchical\_anomaly\_detection.},
  archiveprefix = {arXiv},
  eprint = {2006.10848},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Schirrmeister et al_2020_Understanding Anomaly Detection with Deep Invertible Networks through.pdf},
  journal = {arXiv:2006.10848 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,I.2.6,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{schulzRestrictingFlowInformation2020,
  title = {Restricting the {{Flow}}: {{Information Bottlenecks}} for {{Attribution}}},
  shorttitle = {Restricting the {{Flow}}},
  author = {Schulz, Karl and Sixt, Leon and Tombari, Federico and Landgraf, Tim},
  year = {2020},
  month = may,
  abstract = {Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work we adapt the information bottleneck concept for attribution. By adding noise to intermediate feature maps we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method's information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. For reviews: https://openreview.net/forum?id=S1xWh1rYwB For code: https://github.com/BioroboticsLab/IBA},
  archiveprefix = {arXiv},
  eprint = {2001.00396},
  eprinttype = {arxiv},
  file = {/home/selflein/Zotero/storage/FZRRYH8I/Schulz et al. - 2020 - Restricting the Flow Information Bottlenecks for .pdf;/home/selflein/Zotero/storage/7U667ZKI/2001.html},
  journal = {arXiv:2001.00396 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{sensoyEvidentialDeepLearning2018,
  title = {Evidential {{Deep Learning}} to {{Quantify Classification Uncertainty}}},
  author = {Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  year = {2018},
  month = oct,
  abstract = {Deterministic neural nets have been shown to learn effective predictors on a wide range of machine learning problems. However, as the standard approach is to train the network to minimize a prediction loss, the resultant model remains ignorant to its prediction confidence. Orthogonally to Bayesian neural nets that indirectly infer prediction uncertainty through weight uncertainties, we propose explicit modeling of the same using the theory of subjective logic. By placing a Dirichlet distribution on the class probabilities, we treat predictions of a neural net as subjective opinions and learn the function that collects the evidence leading to these opinions by a deterministic neural net from data. The resultant predictor for a multi-class classification problem is another Dirichlet distribution whose parameters are set by the continuous output of a neural net. We provide a preliminary analysis on how the peculiarities of our new loss function drive improved uncertainty estimation. We observe that our method achieves unprecedented success on detection of out-of-distribution queries and endurance against adversarial perturbations.},
  archiveprefix = {arXiv},
  eprint = {1806.01768},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Sensoy et al_2018_Evidential Deep Learning to Quantify Classification Uncertainty.pdf},
  journal = {arXiv:1806.01768 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{serraInputComplexityOutofdistribution2020,
  title = {Input Complexity and Out-of-Distribution Detection with Likelihood-Based Generative Models},
  author = {Serr{\`a}, Joan and {\'A}lvarez, David and G{\'o}mez, Vicen{\c c} and Slizovskaia, Olga and N{\'u}{\~n}ez, Jos{\'e} F. and Luque, Jordi},
  year = {2020},
  month = jan,
  abstract = {Likelihood-based generative models are a promising resource to detect out-of-distribution (OOD) inputs which could compromise the robustness or reliability of a machine learning system. However, likelihoods derived from such models have been shown to be problematic for detecting certain types of inputs that significantly differ from training data. In this paper, we pose that this problem is due to the excessive influence that input complexity has in generative models' likelihoods. We report a set of experiments supporting this hypothesis, and use an estimate of input complexity to derive an efficient and parameter-free OOD score, which can be seen as a likelihood-ratio, akin to Bayesian model comparison. We find such score to perform comparably to, or even better than, existing OOD detection approaches under a wide range of data sets, models, model sizes, and complexity estimates.},
  archiveprefix = {arXiv},
  eprint = {1909.11480},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Serr√† et al_2020_Input complexity and out-of-distribution detection with likelihood-based.pdf},
  journal = {arXiv:1909.11480 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{shalevOutofDistributionDetectionUsing2019,
  title = {Out-of-{{Distribution Detection}} Using {{Multiple Semantic Label Representations}}},
  author = {Shalev, Gabi and Adi, Yossi and Keshet, Joseph},
  year = {2019},
  month = jan,
  abstract = {Deep Neural Networks are powerful models that attained remarkable results on a variety of tasks. These models are shown to be extremely efficient when training and test data are drawn from the same distribution. However, it is not clear how a network will act when it is fed with an out-of-distribution example. In this work, we consider the problem of out-of-distribution detection in neural networks. We propose to use multiple semantic dense representations instead of sparse representation as the target label. Specifically, we propose to use several word representations obtained from different corpora or architectures as target labels. We evaluated the proposed model on computer vision, and speech commands detection tasks and compared it to previous methods. Results suggest that our method compares favorably with previous work. Besides, we present the efficiency of our approach for detecting wrongly classified and adversarial examples.},
  archiveprefix = {arXiv},
  eprint = {1808.06664},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Shalev et al_2019_Out-of-Distribution Detection using Multiple Semantic Label Representations.pdf},
  journal = {arXiv:1808.06664 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{sonderbyAmortisedMAPInference2017,
  title = {Amortised {{MAP Inference}} for {{Image Super}}-Resolution},
  author = {S{\o}nderby, Casper Kaae and Caballero, Jose and Theis, Lucas and Shi, Wenzhe and Husz{\'a}r, Ferenc},
  year = {2017},
  month = feb,
  abstract = {Image super-resolution (SR) is an underdetermined inverse problem, where a large number of plausible high-resolution images can explain the same downsampled image. Most current single image SR methods use empirical risk minimisation, often with a pixel-wise mean squared error (MSE) loss. However, the outputs from such methods tend to be blurry, over-smoothed and generally appear implausible. A more desirable approach would employ Maximum a Posteriori (MAP) inference, preferring solutions that always have a high probability under the image prior, and thus appear more plausible. Direct MAP estimation for SR is non-trivial, as it requires us to build a model for the image prior from samples. Furthermore, MAP inference is often performed via optimisation-based iterative algorithms which don't compare well with the efficiency of neural-network-based alternatives. Here we introduce new methods for amortised MAP inference whereby we calculate the MAP estimate directly using a convolutional neural network. We first introduce a novel neural network architecture that performs a projection to the affine subspace of valid SR solutions ensuring that the high resolution output of the network is always consistent with the low resolution input. We show that, using this architecture, the amortised MAP inference problem reduces to minimising the cross-entropy between two distributions, similar to training generative models. We propose three methods to solve this optimisation problem: (1) Generative Adversarial Networks (GAN) (2) denoiser-guided SR which backpropagates gradient-estimates from denoising to train the network, and (3) a baseline method using a maximum-likelihood-trained image prior. Our experiments show that the GAN based approach performs best on real image data. Lastly, we establish a connection between GANs and amortised variational inference as in e.g. variational autoencoders.},
  archiveprefix = {arXiv},
  eprint = {1610.04490},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/S√∏nderby et al_2017_Amortised MAP Inference for Image Super-resolution.pdf},
  journal = {arXiv:1610.04490 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{songGenerativeModelingEstimating2020,
  title = {Generative {{Modeling}} by {{Estimating Gradients}} of the {{Data Distribution}}},
  author = {Song, Yang and Ermon, Stefano},
  year = {2020},
  month = oct,
  abstract = {We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise, and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.},
  archiveprefix = {arXiv},
  eprint = {1907.05600},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Song_Ermon_2020_Generative Modeling by Estimating Gradients of the Data Distribution.pdf},
  journal = {arXiv:1907.05600 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{songHowTrainYour2021,
  title = {How to {{Train Your Energy}}-{{Based Models}}},
  author = {Song, Yang and Kingma, Diederik P.},
  year = {2021},
  month = jan,
  abstract = {Energy-Based Models (EBMs), also known as non-normalized probabilistic models, specify probability density or mass functions up to an unknown normalizing constant. Unlike most other probabilistic models, EBMs do not place a restriction on the tractability of the normalizing constant, thus are more flexible to parameterize and can model a more expressive family of probability distributions. However, the unknown normalizing constant of EBMs makes training particularly difficult. Our goal is to provide a friendly introduction to modern approaches for EBM training. We start by explaining maximum likelihood training with Markov chain Monte Carlo (MCMC), and proceed to elaborate on MCMC-free approaches, including Score Matching (SM) and Noise Constrastive Estimation (NCE). We highlight theoretical connections among these three approaches, and end with a brief survey on alternative training methods, which are still under active research. Our tutorial is targeted at an audience with basic understanding of generative models who want to apply EBMs or start a research project in this direction.},
  archiveprefix = {arXiv},
  eprint = {2101.03288},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Song_Kingma_2021_How to Train Your Energy-Based Models.pdf},
  journal = {arXiv:2101.03288 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{songSlicedScoreMatching2019,
  title = {Sliced {{Score Matching}}: {{A Scalable Approach}} to {{Density}} and {{Score Estimation}}},
  shorttitle = {Sliced {{Score Matching}}},
  author = {Song, Yang and Garg, Sahaj and Shi, Jiaxin and Ermon, Stefano},
  year = {2019},
  month = jun,
  abstract = {Score matching is a popular method for estimating unnormalized statistical models. However, it has been so far limited to simple, shallow models or low-dimensional data, due to the difficulty of computing the Hessian of log-density functions. We show this difficulty can be mitigated by projecting the scores onto random vectors before comparing them. This objective, called sliced score matching, only involves Hessian-vector products, which can be easily implemented using reverse-mode automatic differentiation. Therefore, sliced score matching is amenable to more complex models and higher dimensional data compared to score matching. Theoretically, we prove the consistency and asymptotic normality of sliced score matching estimators. Moreover, we demonstrate that sliced score matching can be used to learn deep score estimators for implicit distributions. In our experiments, we show sliced score matching can learn deep energy-based models effectively, and can produce accurate score estimates for applications such as variational inference with implicit distributions and training Wasserstein Auto-Encoders.},
  archiveprefix = {arXiv},
  eprint = {1905.07088},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Song et al_2019_Sliced Score Matching.pdf},
  journal = {arXiv:1905.07088 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{sricharanBuildingRobustClassifiers2018,
  title = {Building Robust Classifiers through Generation of Confident out of Distribution Examples},
  author = {Sricharan, Kumar and Srivastava, Ashok},
  year = {2018},
  month = dec,
  abstract = {Deep learning models are known to be overconfident in their predictions on out of distribution inputs. There have been several pieces of work to address this issue, including a number of approaches for building Bayesian neural networks, as well as closely related work on detection of out of distribution samples. Recently, there has been work on building classifiers that are robust to out of distribution samples by adding a regularization term that maximizes the entropy of the classifier output on out of distribution data. To approximate out of distribution samples (which are not known apriori), a GAN was used for generation of samples at the edges of the training distribution. In this paper, we introduce an alternative GAN based approach for building a robust classifier, where the idea is to use the GAN to explicitly generate out of distribution samples that the classifier is confident on (low entropy), and have the classifier maximize the entropy for these samples. We showcase the effectiveness of our approach relative to state-of-the-art on hand-written characters as well as on a variety of natural image datasets.},
  archiveprefix = {arXiv},
  eprint = {1812.00239},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Sricharan_Srivastava_2018_Building robust classifiers through generation of confident out of distribution.pdf},
  journal = {arXiv:1812.00239 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{stutzConfidenceCalibratedAdversarialTraining2020,
  title = {Confidence-{{Calibrated Adversarial Training}}: {{Generalizing}} to {{Unseen Attacks}}},
  shorttitle = {Confidence-{{Calibrated Adversarial Training}}},
  author = {Stutz, David and Hein, Matthias and Schiele, Bernt},
  year = {2020},
  month = jun,
  abstract = {Adversarial training yields robust models against a specific threat model, e.g., \$L\_\textbackslash infty\$ adversarial examples. Typically robustness does not generalize to previously unseen threat models, e.g., other \$L\_p\$ norms, or larger perturbations. Our confidence-calibrated adversarial training (CCAT) tackles this problem by biasing the model towards low confidence predictions on adversarial examples. By allowing to reject examples with low confidence, robustness generalizes beyond the threat model employed during training. CCAT, trained only on \$L\_\textbackslash infty\$ adversarial examples, increases robustness against larger \$L\_\textbackslash infty\$, \$L\_2\$, \$L\_1\$ and \$L\_0\$ attacks, adversarial frames, distal adversarial examples and corrupted examples and yields better clean accuracy compared to adversarial training. For thorough evaluation we developed novel white- and black-box attacks directly attacking CCAT by maximizing confidence. For each threat model, we use \$7\$ attacks with up to \$50\$ restarts and \$5000\$ iterations and report worst-case robust test error, extended to our confidence-thresholded setting, across all attacks.},
  archiveprefix = {arXiv},
  eprint = {1910.06259},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Stutz et al_2020_Confidence-Calibrated Adversarial Training.pdf},
  journal = {arXiv:1910.06259 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{theisNoteEvaluationGenerative2016,
  title = {A Note on the Evaluation of Generative Models},
  author = {Theis, Lucas and van den Oord, A{\"a}ron and Bethge, Matthias},
  year = {2016},
  month = apr,
  abstract = {Probabilistic generative models can be used for compression, denoising, inpainting, texture synthesis, semi-supervised learning, unsupervised feature learning, and other tasks. Given this wide range of applications, it is not surprising that a lot of heterogeneity exists in the way these models are formulated, trained, and evaluated. As a consequence, direct comparison between models is often difficult. This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models with a focus on image models. In particular, we show that three of the currently most commonly used criteria---average log-likelihood, Parzen window estimates, and visual fidelity of samples---are largely independent of each other when the data is high-dimensional. Good performance with respect to one criterion therefore need not imply good performance with respect to the other criteria. Our results show that extrapolation from one criterion to another is not warranted and generative models need to be evaluated directly with respect to the application(s) they were intended for. In addition, we provide examples demonstrating that Parzen window estimates should generally be avoided.},
  archiveprefix = {arXiv},
  eprint = {1511.01844},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Theis et al_2016_A note on the evaluation of generative models.pdf},
  journal = {arXiv:1511.01844 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@inproceedings{tielemanTrainingRestrictedBoltzmann2008,
  title = {Training Restricted {{Boltzmann}} Machines Using Approximations to the Likelihood Gradient},
  booktitle = {{{ICML}} '08},
  author = {Tieleman, Tijmen},
  year = {2008},
  doi = {10.1145/1390156.1390290},
  abstract = {A new algorithm for training Restricted Boltzmann Machines is introduced. The algorithm, named Persistent Contrastive Divergence, is different from the standard Contrastive Divergence algorithms in that it aims to draw samples from almost exactly the model distribution. It is compared to some standard Contrastive Divergence and Pseudo-Likelihood algorithms on the tasks of modeling and classifying various types of data. The Persistent Contrastive Divergence algorithm outperforms the other algorithms, and is equally fast and simple.},
  file = {/home/selflein/Documents/Zotero/papers/Tieleman_2008_Training restricted Boltzmann machines using approximations to the likelihood.pdf}
}

@inproceedings{tielemanTrainingRestrictedBoltzmann2008a,
  title = {Training Restricted {{Boltzmann}} Machines Using Approximations to the Likelihood Gradient},
  booktitle = {Proceedings of the 25th International Conference on {{Machine}} Learning},
  author = {Tieleman, Tijmen},
  year = {2008},
  month = jul,
  pages = {1064--1071},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1390156.1390290},
  abstract = {A new algorithm for training Restricted Boltzmann Machines is introduced. The algorithm, named Persistent Contrastive Divergence, is different from the standard Contrastive Divergence algorithms in that it aims to draw samples from almost exactly the model distribution. It is compared to some standard Contrastive Divergence and Pseudo-Likelihood algorithms on the tasks of modeling and classifying various types of data. The Persistent Contrastive Divergence algorithm outperforms the other algorithms, and is equally fast and simple.},
  file = {/home/selflein/Documents/Zotero/papers/Tieleman_2008_Training restricted Boltzmann machines using approximations to the likelihood2.pdf},
  isbn = {978-1-60558-205-4},
  series = {{{ICML}} '08}
}

@book{tielemanUsingFastWeights,
  title = {Using {{Fast Weights}} to {{Improve Persistent Contrastive Divergence}}},
  author = {Tieleman, Tijmen and Hinton, Geoffrey},
  abstract = {The most commonly used learning algorithm for restricted Boltzmann machines is contrastive divergence which starts a Markov chain at a data point and runs the chain for only a few iterations to get a cheap, low variance estimate of the sufficient statistics under the model. Tieleman (2008) showed that better learning can be achieved by estimating the model's statistics using a small set of persistent ''fantasy particles '' that are not reinitialized to data points after each weight update. With sufficiently small weight updates, the fantasy particles represent the equilibrium distribution accurately but to explain why the method works with much larger weight updates it is necessary to consider the interaction between the weight updates and the Markov chain. We show that the weight updates force the Markov chain to mix fast, and using this insight we develop an even faster mixing chain that uses an auxiliary set of ''fast weights '' to implement a temporary overlay on the energy landscape. The fast weights learn rapidly but also decay rapidly and do not contribute to the normal energy landscape that defines the model. 1.},
  file = {/home/selflein/Documents/Zotero/papers/Tieleman_Hinton_Using Fast Weights to Improve Persistent Contrastive Divergence.pdf}
}

@article{titsiasUnbiasedImplicitVariational2019,
  title = {Unbiased {{Implicit Variational Inference}}},
  author = {Titsias, Michalis K. and Ruiz, Francisco J. R.},
  year = {2019},
  month = feb,
  abstract = {We develop unbiased implicit variational inference (UIVI), a method that expands the applicability of variational inference by defining an expressive variational family. UIVI considers an implicit variational distribution obtained in a hierarchical manner using a simple reparameterizable distribution whose variational parameters are defined by arbitrarily flexible deep neural networks. Unlike previous works, UIVI directly optimizes the evidence lower bound (ELBO) rather than an approximation to the ELBO. We demonstrate UIVI on several models, including Bayesian multinomial logistic regression and variational autoencoders, and show that UIVI achieves both tighter ELBO and better predictive performance than existing approaches at a similar computational cost.},
  archiveprefix = {arXiv},
  eprint = {1808.02078},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Titsias_Ruiz_2019_Unbiased Implicit Variational Inference.pdf},
  journal = {arXiv:1808.02078 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{tomczakImprovingVariationalAutoEncoders2017,
  title = {Improving {{Variational Auto}}-{{Encoders}} Using {{Householder Flow}}},
  author = {Tomczak, Jakub M. and Welling, Max},
  year = {2017},
  month = jan,
  abstract = {Variational auto-encoders (VAE) are scalable and powerful generative models. However, the choice of the variational posterior determines tractability and flexibility of the VAE. Commonly, latent variables are modeled using the normal distribution with a diagonal covariance matrix. This results in computational efficiency but typically it is not flexible enough to match the true posterior distribution. One fashion of enriching the variational posterior distribution is application of normalizing flows, i.e., a series of invertible transformations to latent variables with a simple posterior. In this paper, we follow this line of thinking and propose a volume-preserving flow that uses a series of Householder transformations. We show empirically on MNIST dataset and histopathology data that the proposed flow allows to obtain more flexible variational posterior and competitive results comparing to other normalizing flows.},
  archiveprefix = {arXiv},
  eprint = {1611.09630},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Tomczak_Welling_2017_Improving Variational Auto-Encoders using Householder Flow.pdf},
  journal = {arXiv:1611.09630 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@misc{UCIMachineLearning2021,
  title = {{{UCI Machine Learning Repository}}: {{Citation Policy}}},
  shorttitle = {{{UCI Machine Learning Repository}}},
  year = {2021},
  month = apr,
  howpublished = {https://web.archive.org/web/20210403082210/https://archive.ics.uci.edu/ml/citation\_policy.html}
}

@article{ulmerKnowYourLimits2021,
  title = {Know {{Your Limits}}: {{Uncertainty Estimation}} with {{ReLU Classifiers Fails}} at {{Reliable OOD Detection}}},
  shorttitle = {Know {{Your Limits}}},
  author = {Ulmer, Dennis and Cin{\`a}, Giovanni},
  year = {2021},
  month = feb,
  abstract = {A crucial requirement for reliable deployment of deep learning models for safety-critical applications is the ability to identify out-of-distribution (OOD) data points, samples which differ from the training data and on which a model might underperform. Previous work has attempted to tackle this problem using uncertainty estimation techniques. However, there is empirical evidence that a large family of these techniques do not detect OOD reliably in classification tasks. This paper gives a theoretical explanation for said experimental findings and illustrates it on synthetic data. We prove that such techniques are not able to reliably identify OOD samples in a classification setting, since their level of confidence is generalized to unseen areas of the feature space. This result stems from the interplay between the representation of ReLU networks as piece-wise affine transformations, the saturating nature of activation functions like softmax, and the most widely-used uncertainty metrics.},
  archiveprefix = {arXiv},
  eprint = {2012.05329},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Ulmer_Cin√†_2021_Know Your Limits.pdf},
  journal = {arXiv:2012.05329 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryclass = {cs}
}

@article{vanamersfoortImprovingDeterministicUncertainty2021,
  title = {Improving {{Deterministic Uncertainty Estimation}} in {{Deep Learning}} for {{Classification}} and {{Regression}}},
  author = {{van Amersfoort}, Joost and Smith, Lewis and Jesson, Andrew and Key, Oscar and Gal, Yarin},
  year = {2021},
  month = feb,
  abstract = {We propose a new model that estimates uncertainty in a single forward pass and works on both classification and regression problems. Our approach combines a bi-Lipschitz feature extractor with an inducing point approximate Gaussian process, offering robust and principled uncertainty estimation. This can be seen as a refinement of Deep Kernel Learning (DKL), with our changes allowing DKL to match softmax neural networks accuracy. Our method overcomes the limitations of previous work addressing deterministic uncertainty quantification, such as the dependence of uncertainty on ad hoc hyper-parameters. Our method matches SotA accuracy, 96.2\% on CIFAR-10, while maintaining the speed of softmax models, and provides uncertainty estimates that outperform previous single forward pass uncertainty models. Finally, we demonstrate our method on a recently introduced benchmark for uncertainty in regression: treatment deferral in causal models for personalized medicine.},
  archiveprefix = {arXiv},
  eprint = {2102.11409},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/van Amersfoort et al_2021_Improving Deterministic Uncertainty Estimation in Deep Learning for.pdf},
  journal = {arXiv:2102.11409 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Gaussian Process,Statistics - Machine Learning,Uncertainty Estimation},
  primaryclass = {cs, stat}
}

@article{vanamersfoortUncertaintyEstimationUsing2020,
  title = {Uncertainty {{Estimation Using}} a {{Single Deep Deterministic Neural Network}}},
  author = {{van Amersfoort}, Joost and Smith, Lewis and Teh, Yee Whye and Gal, Yarin},
  year = {2020},
  month = jun,
  abstract = {We propose a method for training a deterministic deep model that can find and reject out of distribution data points at test time with a single forward pass. Our approach, deterministic uncertainty quantification (DUQ), builds upon ideas of RBF networks. We scale training in these with a novel loss function and centroid updating scheme and match the accuracy of softmax models. By enforcing detectability of changes in the input using a gradient penalty, we are able to reliably detect out of distribution data. Our uncertainty quantification scales well to large datasets, and using a single model, we improve upon or match Deep Ensembles in out of distribution detection on notable difficult dataset pairs such as FashionMNIST vs. MNIST, and CIFAR-10 vs. SVHN.},
  archiveprefix = {arXiv},
  eprint = {2003.02037},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/van Amersfoort et al_2020_Uncertainty Estimation Using a Single Deep Deterministic Neural Network.pdf},
  journal = {arXiv:2003.02037 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Uncertainty Estimation},
  primaryclass = {cs, stat}
}

@inproceedings{varshneyEngineeringSafetyMachine2016,
  title = {Engineering Safety in Machine Learning},
  booktitle = {2016 {{Information Theory}} and {{Applications Workshop}} ({{ITA}})},
  author = {Varshney, Kush R.},
  year = {2016},
  month = jan,
  pages = {1--5},
  doi = {10.1109/ITA.2016.7888195},
  abstract = {Machine learning algorithms are increasingly influencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through interpretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.},
  file = {/home/selflein/Documents/Zotero/papers/Varshney_2016_Engineering safety in machine learning.pdf},
  keywords = {Learning systems,Machine learning algorithms,Risk management,Safety,Sociotechnical systems,Training,Uncertainty}
}

@article{vyasOutofDistributionDetectionUsing2018,
  title = {Out-of-{{Distribution Detection Using}} an {{Ensemble}} of {{Self Supervised Leave}}-out {{Classifiers}}},
  author = {Vyas, Apoorv and Jammalamadaka, Nataraj and Zhu, Xia and Das, Dipankar and Kaul, Bharat and Willke, Theodore L.},
  year = {2018},
  month = sep,
  abstract = {As deep learning methods form a critical part in commercially important applications such as autonomous driving and medical diagnostics, it is important to reliably detect out-of-distribution (OOD) inputs while employing these algorithms. In this work, we propose an OOD detection algorithm which comprises of an ensemble of classifiers. We train each classifier in a self-supervised manner by leaving out a random subset of training data as OOD data and the rest as in-distribution (ID) data. We propose a novel margin-based loss over the softmax output which seeks to maintain at least a margin \$m\$ between the average entropy of the OOD and in-distribution samples. In conjunction with the standard cross-entropy loss, we minimize the novel loss to train an ensemble of classifiers. We also propose a novel method to combine the outputs of the ensemble of classifiers to obtain OOD detection score and class prediction. Overall, our method convincingly outperforms Hendrycks et al.[7] and the current state-of-the-art ODIN[13] on several OOD detection benchmarks.},
  archiveprefix = {arXiv},
  eprint = {1809.03576},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Vyas et al_2018_Out-of-Distribution Detection Using an Ensemble of Self Supervised Leave-out.pdf},
  journal = {arXiv:1809.03576 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@inproceedings{wellingBayesianLearningStochastic2011,
  title = {Bayesian Learning via Stochastic Gradient Langevin Dynamics},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{International Conference}} on {{Machine Learning}}},
  author = {Welling, Max and Teh, Yee Whye},
  year = {2011},
  month = jun,
  pages = {681--688},
  publisher = {{Omnipress}},
  address = {{Madison, WI, USA}},
  abstract = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a "sampling threshold" and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients.},
  isbn = {978-1-4503-0619-5},
  series = {{{ICML}}'11}
}

@article{wenliangLearningDeepKernels2021,
  title = {Learning Deep Kernels for Exponential Family Densities},
  author = {Wenliang, Li and Sutherland, Danica J. and Strathmann, Heiko and Gretton, Arthur},
  year = {2021},
  month = jan,
  abstract = {The kernel exponential family is a rich class of distributions, which can be fit efficiently and with statistical guarantees by score matching. Being required to choose a priori a simple kernel such as the Gaussian, however, limits its practical applicability. We provide a scheme for learning a kernel parameterized by a deep network, which can find complex location-dependent local features of the data geometry. This gives a very rich class of density models, capable of fitting complex structures on moderate-dimensional problems. Compared to deep density models fit via maximum likelihood, our approach provides a complementary set of strengths and tradeoffs: in empirical studies, the former can yield higher likelihoods, whereas the latter gives better estimates of the gradient of the log density, the score, which describes the distribution's shape.},
  archiveprefix = {arXiv},
  eprint = {1811.08357},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Wenliang et al_2021_Learning deep kernels for exponential family densities.pdf},
  journal = {arXiv:1811.08357 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryclass = {cs, stat}
}

@article{winkensContrastiveTrainingImproved2020,
  title = {Contrastive {{Training}} for {{Improved Out}}-of-{{Distribution Detection}}},
  author = {Winkens, Jim and Bunel, Rudy and Roy, Abhijit Guha and Stanforth, Robert and Natarajan, Vivek and Ledsam, Joseph R. and MacWilliams, Patricia and Kohli, Pushmeet and Karthikesalingam, Alan and Kohl, Simon and Cemgil, Taylan and Eslami, S. M. Ali and Ronneberger, Olaf},
  year = {2020},
  month = jul,
  abstract = {Reliable detection of out-of-distribution (OOD) inputs is increasingly understood to be a precondition for deployment of machine learning systems. This paper proposes and investigates the use of contrastive training to boost OOD detection performance. Unlike leading methods for OOD detection, our approach does not require access to examples labeled explicitly as OOD, which can be difficult to collect in practice. We show in extensive experiments that contrastive training significantly helps OOD detection performance on a number of common benchmarks. By introducing and employing the Confusion Log Probability (CLP) score, which quantifies the difficulty of the OOD detection task by capturing the similarity of inlier and outlier datasets, we show that our method especially improves performance in the `near OOD' classes -- a particularly challenging setting for previous methods.},
  archiveprefix = {arXiv},
  eprint = {2007.05566},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Winkens et al_2020_Contrastive Training for Improved Out-of-Distribution Detection.pdf},
  journal = {arXiv:2007.05566 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{xiaoFashionMNISTNovelImage2017,
  title = {Fashion-{{MNIST}}: A {{Novel Image Dataset}} for {{Benchmarking Machine Learning Algorithms}}},
  shorttitle = {Fashion-{{MNIST}}},
  author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  year = {2017},
  month = sep,
  abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
  archiveprefix = {arXiv},
  eprint = {1708.07747},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Xiao et al_2017_Fashion-MNIST.pdf},
  journal = {arXiv:1708.07747 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{xiaoLikelihoodRegretOutofDistribution2020,
  title = {Likelihood {{Regret}}: {{An Out}}-of-{{Distribution Detection Score For Variational Auto}}-Encoder},
  shorttitle = {Likelihood {{Regret}}},
  author = {Xiao, Zhisheng and Yan, Qing and Amit, Yali},
  year = {2020},
  month = oct,
  abstract = {Deep probabilistic generative models enable modeling the likelihoods of very high dimensional data. An important application of generative modeling should be the ability to detect out-of-distribution (OOD) samples by setting a threshold on the likelihood. However, some recent studies show that probabilistic generative models can, in some cases, assign higher likelihoods on certain types of OOD samples, making the OOD detection rules based on likelihood threshold problematic. To address this issue, several OOD detection methods have been proposed for deep generative models. In this paper, we make the observation that many of these methods fail when applied to generative models based on Variational Auto-encoders (VAE). As an alternative, we propose Likelihood Regret, an efficient OOD score for VAEs. We benchmark our proposed method over existing approaches, and empirical results suggest that our method obtains the best overall OOD detection performances when applied to VAEs.},
  archiveprefix = {arXiv},
  eprint = {2003.02977},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Xiao et al_2020_Likelihood Regret.pdf},
  journal = {arXiv:2003.02977 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{xiaoVAEBMSymbiosisVariational2021,
  title = {{{VAEBM}}: {{A Symbiosis}} between {{Variational Autoencoders}} and {{Energy}}-Based {{Models}}},
  shorttitle = {{{VAEBM}}},
  author = {Xiao, Zhisheng and Kreis, Karsten and Kautz, Jan and Vahdat, Arash},
  year = {2021},
  month = feb,
  abstract = {Energy-based models (EBMs) have recently been successful in representing complex distributions of small images. However, sampling from them requires expensive Markov chain Monte Carlo (MCMC) iterations that mix slowly in high dimensional pixel space. Unlike EBMs, variational autoencoders (VAEs) generate samples quickly and are equipped with a latent space that enables fast traversal of the data manifold. However, VAEs tend to assign high probability density to regions in data space outside the actual data distribution and often fail at generating sharp images. In this paper, we propose VAEBM, a symbiotic composition of a VAE and an EBM that offers the best of both worlds. VAEBM captures the overall mode structure of the data distribution using a state-of-the-art VAE and it relies on its EBM component to explicitly exclude non-data-like regions from the model and refine the image samples. Moreover, the VAE component in VAEBM allows us to speed up MCMC updates by reparameterizing them in the VAE's latent space. Our experimental results show that VAEBM outperforms state-of-the-art VAEs and EBMs in generative quality on several benchmark image datasets by a large margin. It can generate high-quality images as large as 256\$\textbackslash times\$256 pixels with short MCMC chains. We also demonstrate that VAEBM provides complete mode coverage and performs well in out-of-distribution detection.},
  archiveprefix = {arXiv},
  eprint = {2010.00654},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Xiao et al_2021_VAEBM.pdf},
  journal = {arXiv:2010.00654 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{yuLSUNConstructionLargescale2016,
  title = {{{LSUN}}: {{Construction}} of a {{Large}}-Scale {{Image Dataset}} Using {{Deep Learning}} with {{Humans}} in the {{Loop}}},
  shorttitle = {{{LSUN}}},
  author = {Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  year = {2016},
  month = jun,
  abstract = {While there has been remarkable progress in the performance of visual recognition algorithms, the state-of-the-art models tend to be exceptionally data-hungry. Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models. Lagging behind the growth in model capacity, the available datasets are quickly becoming outdated in terms of size and density. To circumvent this bottleneck, we propose to amplify human effort through a partially automated labeling scheme, leveraging deep learning with humans in the loop. Starting from a large set of candidate images for each category, we iteratively sample a subset, ask people to label them, classify the others with a trained model, split the set into positives, negatives, and unlabeled based on the classification confidence, and then iterate with the unlabeled set. To assess the effectiveness of this cascading procedure and enable further progress in visual recognition research, we construct a new image dataset, LSUN. It contains around one million labeled images for each of 10 scene categories and 20 object categories. We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset.},
  archiveprefix = {arXiv},
  eprint = {1506.03365},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Yu et al_2016_LSUN.pdf},
  journal = {arXiv:1506.03365 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{yuUnsupervisedOutofDistributionDetection2019,
  title = {Unsupervised {{Out}}-of-{{Distribution Detection}} by {{Maximum Classifier Discrepancy}}},
  author = {Yu, Qing and Aizawa, Kiyoharu},
  year = {2019},
  month = aug,
  abstract = {Since deep learning models have been implemented in many commercial applications, it is important to detect out-of-distribution (OOD) inputs correctly to maintain the performance of the models, ensure the quality of the collected data, and prevent the applications from being used for other-than-intended purposes. In this work, we propose a two-head deep convolutional neural network (CNN) and maximize the discrepancy between the two classifiers to detect OOD inputs. We train a two-head CNN consisting of one common feature extractor and two classifiers which have different decision boundaries but can classify in-distribution (ID) samples correctly. Unlike previous methods, we also utilize unlabeled data for unsupervised training and we use these unlabeled data to maximize the discrepancy between the decision boundaries of two classifiers to push OOD samples outside the manifold of the in-distribution (ID) samples, which enables us to detect OOD samples that are far from the support of the ID samples. Overall, our approach significantly outperforms other state-of-the-art methods on several OOD detection benchmarks and two cases of real-world simulation.},
  archiveprefix = {arXiv},
  eprint = {1908.04951},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Yu_Aizawa_2019_Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy.pdf},
  journal = {arXiv:1908.04951 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryclass = {cs}
}

@article{zagoruykoWideResidualNetworks2017,
  title = {Wide {{Residual Networks}}},
  author = {Zagoruyko, Sergey and Komodakis, Nikos},
  year = {2017},
  month = jun,
  abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layer-deep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and significant improvements on ImageNet. Our code and models are available at https://github.com/szagoruyko/wide-residual-networks},
  archiveprefix = {arXiv},
  eprint = {1605.07146},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Zagoruyko_Komodakis_2017_Wide Residual Networks.pdf},
  journal = {arXiv:1605.07146 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryclass = {cs}
}

@article{zhaiDeepStructuredEnergy2016,
  title = {Deep {{Structured Energy Based Models}} for {{Anomaly Detection}}},
  author = {Zhai, Shuangfei and Cheng, Yu and Lu, Weining and Zhang, Zhongfei},
  year = {2016},
  month = jun,
  abstract = {In this paper, we attack the anomaly detection problem by directly modeling the data distribution with deep architectures. We propose deep structured energy based models (DSEBMs), where the energy function is the output of a deterministic deep neural network with structure. We develop novel model architectures to integrate EBMs with different types of data such as static data, sequential data, and spatial data, and apply appropriate model architectures to adapt to the data structure. Our training algorithm is built upon the recent development of score matching \textbackslash cite\{sm\}, which connects an EBM with a regularized autoencoder, eliminating the need for complicated sampling method. Statistically sound decision criterion can be derived for anomaly detection purpose from the perspective of the energy landscape of the data distribution. We investigate two decision criteria for performing anomaly detection: the energy score and the reconstruction error. Extensive empirical studies on benchmark tasks demonstrate that our proposed model consistently matches or outperforms all the competing methods.},
  archiveprefix = {arXiv},
  eprint = {1605.07717},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Zhai et al_2016_Deep Structured Energy Based Models for Anomaly Detection.pdf},
  journal = {arXiv:1605.07717 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{zhouAmortizedConditionalNormalized2021,
  title = {Amortized {{Conditional Normalized Maximum Likelihood}}: {{Reliable Out}} of {{Distribution Uncertainty Estimation}}},
  shorttitle = {Amortized {{Conditional Normalized Maximum Likelihood}}},
  author = {Zhou, Aurick and Levine, Sergey},
  year = {2021},
  month = mar,
  abstract = {While deep neural networks provide good performance for a range of challenging tasks, calibration and uncertainty estimation remain major challenges, especially under distribution shift. In this paper, we propose the amortized conditional normalized maximum likelihood (ACNML) method as a scalable general-purpose approach for uncertainty estimation, calibration, and out-of-distribution robustness with deep networks. Our algorithm builds on the conditional normalized maximum likelihood (CNML) coding scheme, which has minimax optimal properties according to the minimum description length principle, but is computationally intractable to evaluate exactly for all but the simplest of model classes. We propose to use approximate Bayesian inference technqiues to produce a tractable approximation to the CNML distribution. Our approach can be combined with any approximate inference algorithm that provides tractable posterior densities over model parameters. We demonstrate that ACNML compares favorably to a number of prior techniques for uncertainty estimation in terms of calibration on out-of-distribution inputs.},
  archiveprefix = {arXiv},
  eprint = {2011.02696},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Zhou_Levine_2021_Amortized Conditional Normalized Maximum Likelihood.pdf},
  journal = {arXiv:2011.02696 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{zisselmanDeepResidualFlow2020,
  title = {Deep {{Residual Flow}} for {{Out}} of {{Distribution Detection}}},
  author = {Zisselman, Ev and Tamar, Aviv},
  year = {2020},
  month = jul,
  abstract = {The effective application of neural networks in the real-world relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-the-art method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the state-of-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at \$95\textbackslash\%\$, we improve the true negative rate (TNR) from \$56.7\textbackslash\%\$ (current state-of-the-art) to \$77.5\textbackslash\%\$ (ours).},
  archiveprefix = {arXiv},
  eprint = {2001.05419},
  eprinttype = {arxiv},
  file = {/home/selflein/Documents/Zotero/papers/Zisselman_Tamar_2020_Deep Residual Flow for Out of Distribution Detection.pdf},
  journal = {arXiv:2001.05419 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}



\begin{thebibliography}{1}

\bibitem{grathwohlNoMCMCMe2020}
W.~Grathwohl, J.~Kelly, M.~Hashemi, M.~Norouzi, K.~Swersky, and D.~Duvenaud.
\newblock No {{MCMC}} for me: {{Amortized}} sampling for fast and stable
  training of energy-based models.
\newblock {\em arXiv:2010.04230 [cs]}, Oct. 2020.

\bibitem{grathwohlYourClassifierSecretly2020}
W.~Grathwohl, K.-C. Wang, J.-H. Jacobsen, D.~Duvenaud, M.~Norouzi, and
  K.~Swersky.
\newblock Your {{Classifier}} is {{Secretly}} an {{Energy Based Model}} and
  {{You Should Treat}} it {{Like One}}.
\newblock {\em arXiv:1912.03263 [cs, stat]}, Sept. 2020.

\bibitem{hintonTrainingProductsExperts2002}
G.~E. Hinton.
\newblock Training {{Products}} of {{Experts}} by {{Minimizing Contrastive
  Divergence}}.
\newblock {\em Neural Computation}, 14(8):1771--1800, Aug. 2002.

\bibitem{songSlicedScoreMatching2019}
Y.~Song, S.~Garg, J.~Shi, and S.~Ermon.
\newblock Sliced {{Score Matching}}: {{A Scalable Approach}} to {{Density}} and
  {{Score Estimation}}.
\newblock {\em arXiv:1905.07088 [cs, stat]}, June 2019.

\end{thebibliography}
